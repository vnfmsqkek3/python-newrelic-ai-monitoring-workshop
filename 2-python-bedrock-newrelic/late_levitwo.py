"""
Streamlit + Bedrock + New Relic ëª¨ë‹ˆí„°ë§ ì˜ˆì œ (ì§€ì—° ë²„ì „)

ëª¨ë“  boto3.client('bedrock-runtime') í˜¸ì¶œì´ ìë™ìœ¼ë¡œ ëª¨ë‹ˆí„°ë§ë˜ë©°,
ì˜ë„ì ì¸ ì§€ì—° í•¨ìˆ˜ë“¤ì„ í†µí•´ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ë° ëª¨ë‹ˆí„°ë§ ê²€ì¦ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.
"""

import streamlit as st
import boto3
import json
import time
import uuid
import random
import hashlib
import threading
from concurrent.futures import ThreadPoolExecutor
import numpy as np

# ìƒìˆ˜ (ë¼ì´ë¸ŒëŸ¬ë¦¬ import ì „ì— ì •ì˜)
REGION = "ap-northeast-2"
MODEL_ID = "anthropic.claude-3-5-sonnet-20240620-v1:0"
APP_NAME = "gen-ai-bedrock-late"

# import nr_bedrock_observability ë° ì¦‰ì‹œ auto patch í™œì„±í™”
import nr_bedrock_observability
nr_bedrock_observability.enable_auto_patch(application_name=APP_NAME)

from nr_bedrock_observability import (
    create_streamlit_evaluation_ui,
    create_streamlit_nrql_queries,
    get_streamlit_session_info,
    get_sample_nrql_queries
)

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="Bedrock + New Relic (Late)", 
    page_icon="ğŸŒ",
    layout="wide"
)

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "messages" not in st.session_state:
    st.session_state.messages = []
if "user_role_prompt" not in st.session_state:
    st.session_state.user_role_prompt = "ë‹¹ì‹ ì€ ë„ì›€ì´ ë˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤."
if "user_system_prompt" not in st.session_state:
    st.session_state.user_system_prompt = "ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëª…í™•í•˜ê³  ì •í™•í•˜ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”. í•œêµ­ì–´ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”."
if "user_temperature" not in st.session_state:
    st.session_state.user_temperature = 0.7
if "user_top_p" not in st.session_state:
    st.session_state.user_top_p = 0.9
if "last_response_data" not in st.session_state:
    st.session_state.last_response_data = {}

# ì¶”ê°€ ì„¸ì…˜ ìƒíƒœ (ëª¨ë‹ˆí„°ë§ìš©)
if "trace_id" not in st.session_state:
    st.session_state.trace_id = str(uuid.uuid4())
if "conversation_id" not in st.session_state:
    st.session_state.conversation_id = str(uuid.uuid4())
if "current_completion_id" not in st.session_state:
    st.session_state.current_completion_id = None
if "current_system_prompt" not in st.session_state:
    st.session_state.current_system_prompt = None
if "raw_result" not in st.session_state:
    st.session_state.raw_result = {}
if "message_count" not in st.session_state:
    st.session_state.message_count = 0

# ğŸŒ ì§€ì—° ì„¤ì • ì„¸ì…˜ ìƒíƒœ
if "delay_enabled" not in st.session_state:
    st.session_state.delay_enabled = False
if "delay_type" not in st.session_state:
    st.session_state.delay_type = "simple_sleep"
if "delay_duration" not in st.session_state:
    st.session_state.delay_duration = 2.0
if "delay_before_llm" not in st.session_state:
    st.session_state.delay_before_llm = True
if "delay_after_llm" not in st.session_state:
    st.session_state.delay_after_llm = False

# ğŸŒ ì§€ì—° í•¨ìˆ˜ë“¤
def simple_sleep_delay(duration: float):
    """ë‹¨ìˆœ Sleep ì§€ì—°"""
    time.sleep(duration)

def cpu_intensive_delay(duration: float):
    """CPU ì§‘ì•½ì  ì‘ì—…ì„ í†µí•œ ì§€ì—°"""
    start_time = time.time()
    target_time = start_time + duration
    
    # ì˜ë¯¸ì—†ëŠ” í•´ì‹œ ê³„ì‚°ìœ¼ë¡œ CPU ë¶€í•˜ ìƒì„±
    counter = 0
    while time.time() < target_time:
        # SHA256 í•´ì‹œ ê³„ì‚°
        data = f"delay_simulation_{counter}_{random.random()}".encode()
        hashlib.sha256(data).hexdigest()
        counter += 1
        
        # CPU ì ìœ ìœ¨ ì¡°ì ˆì„ ìœ„í•œ ì§§ì€ íœ´ì‹
        if counter % 1000 == 0:
            time.sleep(0.001)

def memory_intensive_delay(duration: float):
    """ë©”ëª¨ë¦¬ ì§‘ì•½ì  ì‘ì—…ì„ í†µí•œ ì§€ì—°"""
    start_time = time.time()
    target_time = start_time + duration
    
    memory_blocks = []
    try:
        while time.time() < target_time:
            # í° ë°°ì—´ ìƒì„± ë° ì‚­ì œ
            block = np.random.rand(100000).astype(np.float64)  # ~800KB
            memory_blocks.append(block)
            
            # ë©”ëª¨ë¦¬ ì •ë¦¬ (ì¼ë¶€ë§Œ)
            if len(memory_blocks) > 10:
                memory_blocks.pop(0)
            
            time.sleep(0.1)  # ë©”ëª¨ë¦¬ í• ë‹¹ ê°„ê²©
    finally:
        # ë©”ëª¨ë¦¬ ì •ë¦¬
        memory_blocks.clear()

def io_simulation_delay(duration: float):
    """I/O ì‘ì—… ì‹œë®¬ë ˆì´ì…˜ì„ í†µí•œ ì§€ì—°"""
    start_time = time.time()
    target_time = start_time + duration
    
    temp_files = []
    try:
        while time.time() < target_time:
            # ì„ì‹œ íŒŒì¼ ìƒì„± ë° ì“°ê¸°
            temp_file = f"/tmp/delay_sim_{uuid.uuid4().hex[:8]}.txt"
            with open(temp_file, 'w') as f:
                for i in range(1000):
                    f.write(f"Line {i}: {random.random()}\n")
            
            temp_files.append(temp_file)
            
            # íŒŒì¼ ì½ê¸°
            with open(temp_file, 'r') as f:
                content = f.read()
            
            time.sleep(0.05)  # I/O ê°„ê²©
            
            # íŒŒì¼ ê°œìˆ˜ ì œí•œ
            if len(temp_files) > 5:
                import os
                try:
                    os.remove(temp_files.pop(0))
                except:
                    pass
    finally:
        # ì„ì‹œ íŒŒì¼ ì •ë¦¬
        import os
        for temp_file in temp_files:
            try:
                os.remove(temp_file)
            except:
                pass

def network_simulation_delay(duration: float):
    """ë„¤íŠ¸ì›Œí¬ ì§€ì—° ì‹œë®¬ë ˆì´ì…˜ (ThreadPoolExecutor ì‚¬ìš©)"""
    start_time = time.time()
    target_time = start_time + duration
    
    def simulate_network_call():
        # ë„¤íŠ¸ì›Œí¬ í˜¸ì¶œ ì‹œë®¬ë ˆì´ì…˜
        time.sleep(random.uniform(0.1, 0.3))
        return f"Response_{random.random()}"
    
    with ThreadPoolExecutor(max_workers=3) as executor:
        futures = []
        while time.time() < target_time:
            # ì—¬ëŸ¬ ê°œì˜ "ë„¤íŠ¸ì›Œí¬ í˜¸ì¶œ" ì œì¶œ
            for _ in range(3):
                future = executor.submit(simulate_network_call)
                futures.append(future)
            
            # ì¼ë¶€ ê²°ê³¼ ê¸°ë‹¤ë¦¬ê¸°
            if len(futures) >= 6:
                for future in futures[:3]:
                    try:
                        result = future.result(timeout=0.5)
                    except:
                        pass
                futures = futures[3:]
            
            time.sleep(0.2)

def mixed_delay(duration: float):
    """ì—¬ëŸ¬ ì§€ì—° ë°©ë²•ì„ ì¡°í•©"""
    portion = duration / 4
    
    # 25%ì”© ê°ê° ë‹¤ë¥¸ ë°©ë²• ì‚¬ìš©
    simple_sleep_delay(portion)
    cpu_intensive_delay(portion)
    memory_intensive_delay(portion)
    io_simulation_delay(portion)

# ì§€ì—° í•¨ìˆ˜ ë§¤í•‘
DELAY_FUNCTIONS = {
    "simple_sleep": ("â° ë‹¨ìˆœ Sleep", simple_sleep_delay),
    "cpu_intensive": ("ğŸ”¥ CPU ì§‘ì•½ì ", cpu_intensive_delay),
    "memory_intensive": ("ğŸ’¾ ë©”ëª¨ë¦¬ ì§‘ì•½ì ", memory_intensive_delay),
    "io_simulation": ("ğŸ“ I/O ì‹œë®¬ë ˆì´ì…˜", io_simulation_delay),
    "network_simulation": ("ğŸŒ ë„¤íŠ¸ì›Œí¬ ì‹œë®¬ë ˆì´ì…˜", network_simulation_delay),
    "mixed": ("ğŸ”€ í˜¼í•© ë°©ë²•", mixed_delay)
}

def apply_delay(stage: str):
    """ì§€ì—° ì ìš©"""
    if not st.session_state.delay_enabled:
        return
    
    should_apply = False
    if stage == "before_llm" and st.session_state.delay_before_llm:
        should_apply = True
    elif stage == "after_llm" and st.session_state.delay_after_llm:
        should_apply = True
    
    if should_apply:
        delay_func_name, delay_func = DELAY_FUNCTIONS[st.session_state.delay_type]
        duration = st.session_state.delay_duration
        
        with st.spinner(f"ğŸŒ {delay_func_name} ì§€ì—° ì¤‘... ({duration}ì´ˆ)"):
            start_time = time.time()
            try:
                delay_func(duration)
                actual_duration = time.time() - start_time
                st.info(f"âœ… ì§€ì—° ì™„ë£Œ: {actual_duration:.2f}ì´ˆ ({stage})")
            except Exception as e:
                actual_duration = time.time() - start_time
                st.warning(f"âš ï¸ ì§€ì—° ì¤‘ ì˜¤ë¥˜: {str(e)} (ì†Œìš”: {actual_duration:.2f}ì´ˆ)")

def get_bedrock_client():
    """ìë™ íŒ¨ì¹˜ê°€ ì ìš©ëœ Bedrock í´ë¼ì´ì–¸íŠ¸ ìƒì„±"""
    client = boto3.client('bedrock-runtime', region_name=REGION)
    return client 

# UI êµ¬ì„±
st.title("ğŸŒ Auto Bedrock + New Relic (ì§€ì—° í…ŒìŠ¤íŠ¸)")
st.caption("nr-bedrock-observability-python v2.4.1 - ìë™ íŒ¨ì¹˜ ëª¨ë“œ + ì§€ì—° ì‹œë®¬ë ˆì´ì…˜")

# ë©”ì¸ ë ˆì´ì•„ì›ƒ
main_col, sidebar_col = st.columns([2, 1])

with sidebar_col:
    st.header("âš™ï¸ ì„¤ì •")
    
    # ğŸŒ ì§€ì—° ì„¤ì • ì„¹ì…˜
    st.subheader("ğŸŒ ì§€ì—° ì„¤ì •")
    
    # ì§€ì—° í™œì„±í™”/ë¹„í™œì„±í™”
    st.session_state.delay_enabled = st.checkbox(
        "ì§€ì—° í™œì„±í™”", 
        value=st.session_state.delay_enabled,
        help="ì²´í¬í•˜ë©´ ì˜ë„ì ì¸ ì§€ì—°ì´ ì ìš©ë©ë‹ˆë‹¤"
    )
    
    if st.session_state.delay_enabled:
        # ì§€ì—° íƒ€ì… ì„ íƒ
        delay_options = list(DELAY_FUNCTIONS.keys())
        delay_labels = [DELAY_FUNCTIONS[key][0] for key in delay_options]
        
        selected_index = delay_options.index(st.session_state.delay_type)
        new_index = st.selectbox(
            "ì§€ì—° ë°©ë²•",
            range(len(delay_options)),
            index=selected_index,
            format_func=lambda x: delay_labels[x],
            help="ë‹¤ì–‘í•œ ì§€ì—° ë°©ë²•ì„ ì„ íƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤"
        )
        st.session_state.delay_type = delay_options[new_index]
        
        # ì§€ì—° ì‹œê°„ ì„¤ì •
        st.session_state.delay_duration = st.slider(
            "ì§€ì—° ì‹œê°„ (ì´ˆ)",
            min_value=0.5,
            max_value=10.0,
            value=st.session_state.delay_duration,
            step=0.5,
            help="ì§€ì—°í•  ì‹œê°„ì„ ì´ˆ ë‹¨ìœ„ë¡œ ì„¤ì •"
        )
        
        # ì§€ì—° ì ìš© ì‹œì 
        st.markdown("**ì§€ì—° ì ìš© ì‹œì :**")
        st.session_state.delay_before_llm = st.checkbox(
            "ğŸš€ LLM í˜¸ì¶œ ì „", 
            value=st.session_state.delay_before_llm,
            help="Bedrock í˜¸ì¶œ ì „ì— ì§€ì—° ì ìš©"
        )
        st.session_state.delay_after_llm = st.checkbox(
            "ğŸ“ LLM ì‘ë‹µ í›„", 
            value=st.session_state.delay_after_llm,
            help="Bedrock ì‘ë‹µ í›„ì— ì§€ì—° ì ìš©"
        )
        
        # ì§€ì—° ì„¤ì • ë¯¸ë¦¬ë³´ê¸°
        with st.expander("ğŸ” ì§€ì—° ì„¤ì • ë¯¸ë¦¬ë³´ê¸°", expanded=False):
            delay_name, _ = DELAY_FUNCTIONS[st.session_state.delay_type]
            st.markdown(f"**ë°©ë²•:** {delay_name}")
            st.markdown(f"**ì‹œê°„:** {st.session_state.delay_duration}ì´ˆ")
            
            stages = []
            if st.session_state.delay_before_llm:
                stages.append("LLM í˜¸ì¶œ ì „")
            if st.session_state.delay_after_llm:
                stages.append("LLM ì‘ë‹µ í›„")
            
            if stages:
                st.markdown(f"**ì ìš© ì‹œì :** {', '.join(stages)}")
                total_delay = st.session_state.delay_duration * len(stages)
                st.markdown(f"**ì˜ˆìƒ ì´ ì§€ì—°:** {total_delay}ì´ˆ")
            else:
                st.warning("ì§€ì—° ì ìš© ì‹œì ì„ ì„ íƒí•´ì£¼ì„¸ìš”")
    
    st.markdown("---")
    
    # ëª¨ë¸ íŒŒë¼ë¯¸í„° ì„¤ì •
    st.header("ëª¨ë¸ íŒŒë¼ë¯¸í„° ì„¤ì •")
    
    # í”„ë¦¬ì…‹ ë²„íŠ¼ë“¤
    st.subheader("ë¹ ë¥¸ ì„¤ì • í”„ë¦¬ì…‹")
    col1, col2, col3 = st.columns(3)
    
    with col1:
        if st.button("ğŸ¥ ì˜ë£Œ ì „ë¬¸ê°€", help="ì˜ë£Œ ê´€ë ¨ ì§ˆë¬¸ì— íŠ¹í™”ëœ ì„¤ì •"):
            st.session_state.user_role_prompt = "ë‹¹ì‹ ì€ 15ë…„ ê²½ë ¥ì˜ ì„ìƒ ì˜ì‚¬ì´ì ë‚´ê³¼ ì „ë¬¸ì˜ì…ë‹ˆë‹¤. í™˜ìë“¤ì—ê²Œ ì‹¤ìš©ì ì´ê³  êµ¬ì²´ì ì¸ ì˜í•™ì  ì¡°ì–¸ì„ ì œê³µí•˜ëŠ” ê²ƒì´ ë‹¹ì‹ ì˜ ì „ë¬¸ ë¶„ì•¼ì…ë‹ˆë‹¤."
            st.session_state.user_system_prompt = """ë‹¤ìŒ ì›ì¹™ì— ë”°ë¼ ì˜í•™ì  ì¡°ì–¸ì„ ì œê³µí•˜ì„¸ìš”:

1. **ì „ë¬¸ì  ì§„ë‹¨ê³¼ ì¹˜ë£Œ ê¶Œê³ **: ì¦ìƒì„ ë¶„ì„í•˜ê³  ê°€ëŠ¥í•œ ì›ì¸ì„ ì œì‹œí•˜ë©°, ì¼ë°˜ì˜ì•½í’ˆì´ë‚˜ ìƒí™œìŠµê´€ ê°œì„  ë“± êµ¬ì²´ì ì¸ í•´ê²°ì±…ì„ ì œì•ˆí•˜ì„¸ìš”.

2. **ë‹¨ê³„ë³„ ì¹˜ë£Œ ì ‘ê·¼**: ê²½ì¦ì˜ ê²½ìš° ìê°€ ê´€ë¦¬ ë°©ë²•ë¶€í„° ì‹œì‘í•˜ì—¬, í•„ìš”ì‹œ ì „ë¬¸ì˜ ì§„ë£Œë¥¼ ê¶Œí•˜ëŠ” ë‹¨ê³„ì  ì ‘ê·¼ë²•ì„ ì‚¬ìš©í•˜ì„¸ìš”.

3. **ì‹¤ìš©ì  ì•½ë¬¼ ì •ë³´**: ì¼ë°˜ì˜ì•½í’ˆì˜ ê²½ìš° êµ¬ì²´ì ì¸ ì„±ë¶„ëª…, ìš©ë²•Â·ìš©ëŸ‰, ì£¼ì˜ì‚¬í•­ì„ ëª…í™•íˆ ì œì‹œí•˜ì„¸ìš”.

4. **ìœ„í—˜ ì‹ í˜¸ ì¸ì‹**: ì‘ê¸‰ ìƒí™©ì´ë‚˜ ì „ë¬¸ì˜ ì§„ë£Œê°€ ë°˜ë“œì‹œ í•„ìš”í•œ ê²½ìš°ë¥¼ ëª…í™•íˆ êµ¬ë¶„í•˜ì—¬ ì•ˆë‚´í•˜ì„¸ìš”.

5. **ê°œì¸í™”ëœ ì¡°ì–¸**: ì—°ë ¹, ê¸°ì¡´ ì§ˆí™˜, ë³µìš© ì¤‘ì¸ ì•½ë¬¼ ë“±ì„ ê³ ë ¤í•œ ë§ì¶¤í˜• ì¡°ì–¸ì„ ì œê³µí•˜ì„¸ìš”.

í•­ìƒ ì˜í•™ì  ê·¼ê±°ë¥¼ ë°”íƒ•ìœ¼ë¡œ í•˜ë˜, í™˜ìê°€ ì‹¤ì œë¡œ í™œìš©í•  ìˆ˜ ìˆëŠ” êµ¬ì²´ì ì´ê³  ì‹¤ìš©ì ì¸ ì •ë³´ë¥¼ ìš°ì„  ì œê³µí•˜ì„¸ìš”. í•œêµ­ì–´ë¡œ ëª…í™•í•˜ê³  ì´í•´í•˜ê¸° ì‰½ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”."""
            st.session_state.user_temperature = 0.2
            st.session_state.user_top_p = 0.8
            st.rerun()
    
    with col2:
        if st.button("ğŸ’» ì½”ë”© íŠœí„°", help="í”„ë¡œê·¸ë˜ë° í•™ìŠµì— íŠ¹í™”ëœ ì„¤ì •"):
            st.session_state.user_role_prompt = "ë‹¹ì‹ ì€ 10ë…„ ì´ìƒì˜ ì‹¤ë¬´ ê²½í—˜ì„ ê°€ì§„ ì‹œë‹ˆì–´ ê°œë°œìì´ì í”„ë¡œê·¸ë˜ë° êµìœ¡ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹¤ì–‘í•œ í”„ë¡œê·¸ë˜ë° ì–¸ì–´ì™€ í”„ë ˆì„ì›Œí¬ì— ëŠ¥í†µí•˜ë©°, ë³µì¡í•œ ê°œë…ì„ ì‰½ê²Œ ì„¤ëª…í•˜ëŠ” ê²ƒì´ íŠ¹ê¸°ì…ë‹ˆë‹¤."
            st.session_state.user_system_prompt = """ë‹¤ìŒ êµìœ¡ ë°©ë²•ë¡ ì— ë”°ë¼ í”„ë¡œê·¸ë˜ë° ì§€ë„ë¥¼ í•´ì£¼ì„¸ìš”:

1. **ë‹¨ê³„ë³„ í•™ìŠµ ì ‘ê·¼**:
   - ê°œë… ì„¤ëª… â†’ ê°„ë‹¨í•œ ì˜ˆì œ â†’ ì‹¤ìŠµ ë¬¸ì œ â†’ ì‹¬í™” ì‘ìš© ìˆœì„œë¡œ ì§„í–‰
   - í•™ìŠµìì˜ ìˆ˜ì¤€ì— ë§ëŠ” ì ì ˆí•œ ë‚œì´ë„ ì¡°ì ˆ

2. **ì‹¤ìŠµ ì¤‘ì‹¬ êµìœ¡**:
   - ëª¨ë“  ê°œë…ì— ëŒ€í•´ ì‹¤í–‰ ê°€ëŠ¥í•œ ì½”ë“œ ì˜ˆì œ ì œê³µ
   - ì£¼ì„ì„ ìƒì„¸íˆ ë‹¬ì•„ ì½”ë“œì˜ ê° ë¶€ë¶„ ì„¤ëª…
   - ì‹¤ì œ í”„ë¡œì íŠ¸ì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ì‹¤ìš©ì ì¸ ì˜ˆì œ ìš°ì„ 

3. **ë””ë²„ê¹…ê³¼ ë¬¸ì œ í•´ê²°**:
   - ìì£¼ ë°œìƒí•˜ëŠ” ì˜¤ë¥˜ì™€ í•´ê²° ë°©ë²• ì„¤ëª…
   - ì½”ë“œ ë¦¬ë·° ê´€ì ì—ì„œ ê°œì„ ì  ì œì‹œ
   - íš¨ìœ¨ì ì¸ ë””ë²„ê¹… ë°©ë²• ì•ˆë‚´

4. **ëª¨ë²” ì‚¬ë¡€ì™€ ì½”ë”© í‘œì¤€**:
   - í´ë¦° ì½”ë“œ ì‘ì„± ì›ì¹™ ì ìš©
   - ì—…ê³„ í‘œì¤€ê³¼ ëª¨ë²” ì‚¬ë¡€ ì†Œê°œ
   - ì„±ëŠ¥ ìµœì í™”ì™€ ìœ ì§€ë³´ìˆ˜ì„± ê³ ë ¤

5. **í•™ìŠµ ë™ê¸° ë¶€ì—¬**:
   - ì‹¤ë¬´ì—ì„œì˜ í™œìš© ì‚¬ë¡€ ì œì‹œ
   - ë‹¨ê³„ë³„ ì„±ì·¨ê° ì œê³µ
   - ì¶”ê°€ í•™ìŠµ ìë£Œì™€ ë°œì „ ë°©í–¥ ì œì•ˆ

í•­ìƒ 'ì™œ ì´ë ‡ê²Œ ì‘ì„±í•˜ëŠ”ê°€?'ì— ëŒ€í•œ ì´ìœ ë¥¼ ì„¤ëª…í•˜ê³ , ëŒ€ì•ˆì  ì ‘ê·¼ë²•ë„ í•¨ê»˜ ì œì‹œí•˜ì„¸ìš”. í•œêµ­ì–´ë¡œ ì¹œê·¼í•˜ê³  ì´í•´í•˜ê¸° ì‰½ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”."""
            st.session_state.user_temperature = 0.4
            st.session_state.user_top_p = 0.9
            st.rerun()
    
    with col3:
        if st.button("ğŸ¨ ì°½ì˜ì  ì‘ê°€", help="ì°½ì‘ í™œë™ì— íŠ¹í™”ëœ ì„¤ì •"):
            st.session_state.user_role_prompt = "ë‹¹ì‹ ì€ ë² ìŠ¤íŠ¸ì…€ëŸ¬ ì‘í’ˆì„ ì—¬ëŸ¬ í¸ ì¶œê°„í•œ ì „ë¬¸ ì‘ê°€ì´ì ì°½ì‘ ì§€ë„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì†Œì„¤, ì—ì„¸ì´, ì‹œë‚˜ë¦¬ì˜¤ ë“± ë‹¤ì–‘í•œ ì¥ë¥´ì— ëŠ¥í†µí•˜ë©°, ë…ìì˜ ë§ˆìŒì„ ì‚¬ë¡œì¡ëŠ” ìŠ¤í† ë¦¬í…”ë§ì´ íŠ¹ê¸°ì…ë‹ˆë‹¤."
            st.session_state.user_system_prompt = """ë‹¤ìŒ ì°½ì‘ ì›ì¹™ì— ë”°ë¼ ê¸€ì“°ê¸° ì§€ë„ë¥¼ í•´ì£¼ì„¸ìš”:

1. **ì°½ì‘ í”„ë¡œì„¸ìŠ¤ ì•ˆë‚´**:
   - ì•„ì´ë””ì–´ ë°œêµ´ â†’ êµ¬ì„± ê³„íš â†’ ì´ˆê³  ì‘ì„± â†’ ìˆ˜ì •/í¸ì§‘ ë‹¨ê³„ë³„ ê°€ì´ë“œ
   - ê° ë‹¨ê³„ì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” êµ¬ì²´ì ì¸ ê¸°ë²•ê³¼ ë„êµ¬ ì œì‹œ

2. **ìŠ¤í† ë¦¬í…”ë§ êµ¬ì¡°**:
   - ë§¤ë ¥ì ì¸ ë„ì…ë¶€, ê¸´ì¥ê° ìˆëŠ” ì „ê°œ, ë§Œì¡±ìŠ¤ëŸ¬ìš´ ê²°ë§ êµ¬ì„±ë²•
   - ìºë¦­í„° ê°œë°œê³¼ ê°ˆë“± êµ¬ì¡° ì„¤ê³„
   - ì¥ë¥´ë³„ íŠ¹ì„±ì„ ê³ ë ¤í•œ ë§ì¶¤í˜• ì¡°ì–¸

3. **ë¬¸ì²´ì™€ í‘œí˜„ë ¥**:
   - ìƒí™©ê³¼ ê°ì •ì— ë§ëŠ” ìƒìƒí•œ ë¬˜ì‚¬ ê¸°ë²•
   - ë…ìì˜ ê³µê°ì„ ì´ëŒì–´ë‚´ëŠ” í‘œí˜„ ë°©ë²•
   - ë¬¸ì¥ ë¦¬ë“¬ê³¼ í˜¸í¡ì„ ê³ ë ¤í•œ ê¸€ì“°ê¸°

4. **ë…ì°½ì„±ê³¼ ì°¨ë³„í™”**:
   - ê¸°ì¡´ ì‘í’ˆê³¼ ì°¨ë³„í™”ë˜ëŠ” ë…íŠ¹í•œ ê´€ì  ì œì‹œ
   - ê°œì¸ì  ê²½í—˜ê³¼ ìƒìƒë ¥ì„ ê²°í•©í•œ ì˜¤ë¦¬ì§€ë„ ì•„ì´ë””ì–´ ê°œë°œ
   - íŠ¸ë Œë“œë¥¼ ë°˜ì˜í•˜ë©´ì„œë„ ì‹œëŒ€ë¥¼ ì´ˆì›”í•˜ëŠ” ë³´í¸ì„± ì¶”êµ¬

5. **ì‹¤ìš©ì  ê¸€ì“°ê¸° ì¡°ì–¸**:
   - ì‘ê°€ì˜ ë¸”ë¡ ê·¹ë³µ ë°©ë²•
   - íš¨ê³¼ì ì¸ ìë£Œ ì¡°ì‚¬ì™€ ì·¨ì¬ ë°©ë²•
   - ì¶œê°„ê³¼ ë…ì ì†Œí†µì„ ìœ„í•œ ì‹¤ë¬´ì  ì¡°ì–¸

í•­ìƒ êµ¬ì²´ì ì¸ ì˜ˆì‹œì™€ í•¨ê»˜ ì„¤ëª…í•˜ê³ , ì°½ì‘ìì˜ ê°œì„±ì„ ì‚´ë¦´ ìˆ˜ ìˆëŠ” ë‹¤ì–‘í•œ ì ‘ê·¼ë²•ì„ ì œì•ˆí•˜ì„¸ìš”. í•œêµ­ì–´ì˜ ì•„ë¦„ë‹¤ì›€ì„ ì‚´ë¦° í’ë¶€í•œ í‘œí˜„ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”."""
            st.session_state.user_temperature = 0.8
            st.session_state.user_top_p = 0.95
            st.rerun()
    
    # Role Prompt
    st.session_state.user_role_prompt = st.text_area(
        "Role Prompt:",
        value=st.session_state.user_role_prompt,
        height=80
    )
    
    # System Prompt  
    st.session_state.user_system_prompt = st.text_area(
        "System Prompt:",
        value=st.session_state.user_system_prompt,
        height=100
    )
    
    # Temperature
    st.session_state.user_temperature = st.slider(
        "Temperature (ì°½ì˜ì„±)",
        0.0, 1.0, 
        st.session_state.user_temperature,
        0.1
    )
    
    # Top-p
    st.session_state.user_top_p = st.slider(
        "Top-p (ë‹¤ì–‘ì„±)",
        0.0, 1.0,
        st.session_state.user_top_p, 
        0.05
    )
    
    # í˜„ì¬ ì„¤ì • í‘œì‹œ
    with st.expander("ğŸ“‹ í˜„ì¬ ì„¤ì •", expanded=False):
        combined_prompt = f"{st.session_state.user_role_prompt}\n\n{st.session_state.user_system_prompt}"
        st.code(combined_prompt)
        st.write(f"Temperature: {st.session_state.user_temperature}")
        st.write(f"Top-p: {st.session_state.user_top_p}")
    
    # ì„¸ì…˜ ì •ë³´ í‘œì‹œ
    st.subheader("ğŸ“Š ì„¸ì…˜ ì •ë³´")
    session_info = get_streamlit_session_info()
    st.code(f"ëŒ€í™” ID: {session_info.get('conversation_id', 'N/A')}")
    st.code(f"ë©”ì‹œì§€ ë²ˆí˜¸: {session_info.get('message_index', 'N/A')}")
    
    # ğŸ› ë””ë²„ê¹…: ëª¨ë‹ˆí„°ë§ ìƒíƒœ í™•ì¸
    st.subheader("ğŸ” ëª¨ë‹ˆí„°ë§ ìƒíƒœ")
    try:
        client = get_bedrock_client()
        is_monitored = hasattr(client.invoke_model, '_nr_monitored')
        is_auto_patched = hasattr(client.invoke_model, '__wrapped__')
        
        st.markdown(f"**ëª¨ë‹ˆí„°ë§ ì ìš©**: {'âœ… ì˜ˆ' if is_monitored else 'âŒ ì•„ë‹ˆì˜¤'}")
        st.markdown(f"**ìë™ íŒ¨ì¹˜**: {'âœ… ì˜ˆ' if is_auto_patched else 'âŒ ì•„ë‹ˆì˜¤'}")
        st.markdown(f"**ì•± ì´ë¦„**: {APP_NAME}")
        
        # boto3 í´ë¼ì´ì–¸íŠ¸ ì •ë³´
        st.code(f"í´ë¼ì´ì–¸íŠ¸ ID: {id(client)}")
        
    except Exception as e:
        st.error(f"ëª¨ë‹ˆí„°ë§ ìƒíƒœ í™•ì¸ ì˜¤ë¥˜: {str(e)}")
    
    # ìƒˆ ëŒ€í™” ì‹œì‘
    if st.button("ğŸ”„ ìƒˆ ëŒ€í™” ì‹œì‘"):
        st.session_state.messages = []
        st.session_state.last_response_data = {}
        # conversation_idëŠ” ìë™ìœ¼ë¡œ ì¬ìƒì„±ë¨
        st.rerun() 

with main_col:
    # ì±„íŒ… ê¸°ë¡ í‘œì‹œ
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])
    
    # ì‚¬ìš©ì ì…ë ¥
    user_input = st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”")
    
    if user_input:
        # ì‚¬ìš©ì ë©”ì‹œì§€ í‘œì‹œ
        with st.chat_message("user"):
            st.markdown(user_input)
        st.session_state.messages.append({"role": "user", "content": user_input})
        
        # AI ì‘ë‹µ ìƒì„±
        with st.chat_message("assistant"):
            with st.spinner("ë‹µë³€ ìƒì„± ì¤‘..."):
                try:
                    start_time = time.time()
                    delay_times = {}
                    
                    # ğŸŒ LLM í˜¸ì¶œ ì „ ì§€ì—° ì ìš©
                    if st.session_state.delay_enabled and st.session_state.delay_before_llm:
                        delay_start = time.time()
                        apply_delay("before_llm")
                        delay_times["before_llm"] = time.time() - delay_start
                    
                    # ğŸš€ ì¼ë°˜ì ì¸ boto3.client í˜¸ì¶œ - ìë™ìœ¼ë¡œ ëª¨ë“  ëª¨ë‹ˆí„°ë§ ì²˜ë¦¬!
                    bedrock_client = get_bedrock_client()
                    
                    # ì²« ë²ˆì§¸ ë©”ì‹œì§€ì¸ ê²½ìš° ëª¨ë‹ˆí„°ë§ ìƒíƒœ í•œ ë²ˆ ë” í™•ì¸
                    if len(st.session_state.messages) <= 1:
                        try:
                            if hasattr(bedrock_client.invoke_model, '__wrapped__'):
                                st.info("ğŸ¯ ì²« ë²ˆì§¸ í˜¸ì¶œ - ëª¨ë‹ˆí„°ë§ í™œì„±í™” í™•ì¸ë¨!")
                            else:
                                st.warning("âš ï¸ ì²« ë²ˆì§¸ í˜¸ì¶œ - ëª¨ë‹ˆí„°ë§ ë¯¸í™•ì¸")
                        except Exception as check_error:
                            st.warning(f"ëª¨ë‹ˆí„°ë§ ì²´í¬ ì˜¤ë¥˜: {str(check_error)}")
                    
                    # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
                    combined_system_prompt = f"{st.session_state.user_role_prompt}\n\n{st.session_state.user_system_prompt}"
                    
                    # Bedrock API í˜¸ì¶œ
                    llm_start_time = time.time()
                    response = bedrock_client.invoke_model(
                        modelId=MODEL_ID,
                        body=json.dumps({
                            "anthropic_version": "bedrock-2023-05-31",
                            "max_tokens": 1000,
                            "temperature": st.session_state.user_temperature,
                            "top_p": st.session_state.user_top_p,
                            "system": combined_system_prompt,
                            "messages": [
                                {
                                    "role": "user",
                                    "content": [{"type": "text", "text": user_input}]
                                }
                            ]
                        })
                    )
                    llm_duration = time.time() - llm_start_time
                    
                    # ğŸŒ LLM ì‘ë‹µ í›„ ì§€ì—° ì ìš©
                    if st.session_state.delay_enabled and st.session_state.delay_after_llm:
                        delay_start = time.time()
                        apply_delay("after_llm")
                        delay_times["after_llm"] = time.time() - delay_start
                    
                    # ì‘ë‹µ ì²˜ë¦¬ (ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ìë™ìœ¼ë¡œ í…ìŠ¤íŠ¸ ì¶”ì¶œ ë° New Relic ì „ì†¡)
                    response_body = json.loads(response['body'].read().decode('utf-8'))
                    
                    # ì‘ë‹µ í…ìŠ¤íŠ¸ ì¶”ì¶œ (fallback)
                    assistant_response = ""
                    if 'content' in response_body:
                        content = response_body['content']
                        if isinstance(content, list) and len(content) > 0:
                            if isinstance(content[0], dict) and 'text' in content[0]:
                                assistant_response = content[0]['text']
                    
                    if assistant_response:
                        st.markdown(assistant_response)
                        st.session_state.messages.append({"role": "assistant", "content": assistant_response})
                        
                        # ì‘ë‹µ ë°ì´í„° ì €ì¥ (í‰ê°€ UIìš©) + ì§€ì—° ì •ë³´ í¬í•¨
                        usage = response_body.get("usage", {})
                        total_duration = int((time.time() - start_time) * 1000)
                        llm_duration_ms = int(llm_duration * 1000)
                        
                        delay_info = {}
                        total_delay_ms = 0
                        for stage, delay_time in delay_times.items():
                            delay_ms = int(delay_time * 1000)
                            delay_info[f"{stage}_delay_ms"] = delay_ms
                            total_delay_ms += delay_ms
                        
                        st.session_state.last_response_data = {
                            "response_time_ms": total_duration,
                            "llm_only_time_ms": llm_duration_ms,
                            "total_delay_ms": total_delay_ms,
                            "total_tokens": usage.get("total_token_count", 0) or (usage.get("input_tokens", 0) + usage.get("output_tokens", 0)),
                            "prompt_tokens": usage.get("input_token_count", 0) or usage.get("input_tokens", 0),
                            "completion_tokens": usage.get("output_token_count", 0) or usage.get("output_tokens", 0),
                            "temperature": st.session_state.user_temperature,
                            "top_p": st.session_state.user_top_p,
                            **delay_info
                        }
                        
                        # ğŸŒ ì§€ì—° ì •ë³´ í‘œì‹œ
                        if st.session_state.delay_enabled and delay_times:
                            with st.expander("ğŸŒ ì§€ì—° ì •ë³´", expanded=False):
                                st.markdown(f"**ì´ ì²˜ë¦¬ ì‹œê°„**: {total_duration}ms")
                                st.markdown(f"**ì‹¤ì œ LLM ì‹œê°„**: {llm_duration_ms}ms")
                                st.markdown(f"**ì´ ì§€ì—° ì‹œê°„**: {total_delay_ms}ms")
                                
                                for stage, delay_time in delay_times.items():
                                    delay_ms = int(delay_time * 1000)
                                    stage_name = "LLM í˜¸ì¶œ ì „" if stage == "before_llm" else "LLM ì‘ë‹µ í›„"
                                    st.markdown(f"- {stage_name}: {delay_ms}ms")
                                
                                efficiency = (llm_duration_ms / total_duration) * 100
                                st.markdown(f"**íš¨ìœ¨ì„±**: {efficiency:.1f}% (ì‹¤ì œ LLM ì‘ì—… ì‹œê°„ ë¹„ìœ¨)")
                        
                    else:
                        st.error("ì‘ë‹µì„ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                        
                except Exception as e:
                    st.error(f"ì˜¤ë¥˜: {str(e)}")

# ğŸ“Š ëª¨ë‹ˆí„°ë§ ì •ë³´ ì„¹ì…˜
st.markdown("---")
col1, col2 = st.columns(2)

with col1:
    st.markdown("### ìë™ ìˆ˜ì§‘ë˜ëŠ” ë°ì´í„°")
    st.markdown("""
    **ìë™ìœ¼ë¡œ New Relicì— ì „ì†¡:**
    - âœ… LlmCompletion (ìš”ì²­/ì‘ë‹µ, í† í°, íŒŒë¼ë¯¸í„°)
    - âœ… LlmUserRole (ì‚¬ìš©ì ì…ë ¥ ì´ë²¤íŠ¸)  
    - âœ… LlmSystemRole (ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì´ë²¤íŠ¸)
    - âœ… LlmBedrockResponse (ì‘ë‹µ ìƒì„¸ ì •ë³´)
    - âœ… trace_id, completion_id (ìë™ ìƒì„±)
    - âœ… conversation_id (ì„¸ì…˜ ì—°ë™)
    
    **ğŸŒ ì§€ì—° í…ŒìŠ¤íŠ¸ ì¶”ê°€ ì •ë³´:**
    - â±ï¸ ì‹¤ì œ LLM ì‘ë‹µ ì‹œê°„
    - ğŸŒ ì˜ë„ì  ì§€ì—° ì‹œê°„
    - ğŸ“Š ì „ì²´ ì²˜ë¦¬ ì‹œê°„ ë° íš¨ìœ¨ì„±
    """)

with col2:
    # New Relic ì¿¼ë¦¬ ì˜ˆì œ (ë¼ì´ë¸ŒëŸ¬ë¦¬ í•¨ìˆ˜ ì‚¬ìš©)
    create_streamlit_nrql_queries(
        application_name=APP_NAME,
        conversation_id=session_info.get('conversation_id')
    )

# ğŸ“ í‰ê°€ UI (ë§ˆì§€ë§‰ ì‘ë‹µì´ ìˆì„ ë•Œë§Œ í‘œì‹œ)
if (st.session_state.messages and 
    st.session_state.messages[-1]["role"] == "assistant" and
    st.session_state.last_response_data):
    
    st.markdown("---")
    
    # ë¼ì´ë¸ŒëŸ¬ë¦¬ì˜ ìë™ í‰ê°€ UI ì‚¬ìš© (New Relic ì „ì†¡ í¬í•¨)
    create_streamlit_evaluation_ui(
        # trace_idì™€ completion_idëŠ” ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ìë™ìœ¼ë¡œ ê´€ë¦¬
        model_id=MODEL_ID,
        response_time_ms=st.session_state.last_response_data.get("response_time_ms"),
        total_tokens=st.session_state.last_response_data.get("total_tokens"),
        prompt_tokens=st.session_state.last_response_data.get("prompt_tokens"),
        completion_tokens=st.session_state.last_response_data.get("completion_tokens"),
        temperature=st.session_state.last_response_data.get("temperature"),
        top_p=st.session_state.last_response_data.get("top_p"),
        application_name=APP_NAME
    )

# ğŸŒ ì§€ì—° í…ŒìŠ¤íŠ¸ ì •ë³´ ì„¹ì…˜
if st.session_state.delay_enabled:
    st.markdown("---")
    st.markdown("### ğŸŒ ì§€ì—° í…ŒìŠ¤íŠ¸ ì •ë³´")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        delay_name, _ = DELAY_FUNCTIONS[st.session_state.delay_type]
        st.metric("ì§€ì—° ë°©ë²•", delay_name)
    
    with col2:
        st.metric("ì§€ì—° ì‹œê°„", f"{st.session_state.delay_duration}ì´ˆ")
    
    with col3:
        stages = []
        if st.session_state.delay_before_llm:
            stages.append("í˜¸ì¶œ ì „")
        if st.session_state.delay_after_llm:
            stages.append("ì‘ë‹µ í›„")
        stage_text = ", ".join(stages) if stages else "ì—†ìŒ"
        st.metric("ì ìš© ì‹œì ", stage_text)
    
    # ì§€ì—° ë°©ë²•ë³„ ì„¤ëª…
    with st.expander("ğŸ” ì§€ì—° ë°©ë²• ì„¤ëª…", expanded=False):
        st.markdown("""
        **â° ë‹¨ìˆœ Sleep**: `time.sleep()`ì„ ì‚¬ìš©í•œ ê¸°ë³¸ì ì¸ ëŒ€ê¸°
        
        **ğŸ”¥ CPU ì§‘ì•½ì **: SHA256 í•´ì‹œ ê³„ì‚°ì„ í†µí•œ CPU ë¶€í•˜ ìƒì„±
        
        **ğŸ’¾ ë©”ëª¨ë¦¬ ì§‘ì•½ì **: ëŒ€ìš©ëŸ‰ ë°°ì—´ ìƒì„±/ì‚­ì œë¥¼ í†µí•œ ë©”ëª¨ë¦¬ ë¶€í•˜
        
        **ğŸ“ I/O ì‹œë®¬ë ˆì´ì…˜**: ì„ì‹œ íŒŒì¼ ìƒì„±/ì½ê¸°/ì“°ê¸° ì‘ì—…
        
        **ğŸŒ ë„¤íŠ¸ì›Œí¬ ì‹œë®¬ë ˆì´ì…˜**: ThreadPoolExecutorë¥¼ ì‚¬ìš©í•œ ë™ì‹œ ë„¤íŠ¸ì›Œí¬ í˜¸ì¶œ ì‹œë®¬ë ˆì´ì…˜
        
        **ğŸ”€ í˜¼í•© ë°©ë²•**: ìœ„ì˜ ëª¨ë“  ë°©ë²•ì„ ìˆœì°¨ì ìœ¼ë¡œ ì‹¤í–‰
        
        ì´ëŸ¬í•œ ë‹¤ì–‘í•œ ì§€ì—° ë°©ë²•ì„ í†µí•´ ì‹¤ì œ ì‹œìŠ¤í…œì—ì„œ ë°œìƒí•  ìˆ˜ ìˆëŠ” ë‹¤ì–‘í•œ ì„±ëŠ¥ ë³‘ëª© ìƒí™©ì„ ì‹œë®¬ë ˆì´ì…˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
        """)

# ğŸ§ª ì§€ì—° í…ŒìŠ¤íŠ¸ ë° ë²¤ì¹˜ë§ˆí¬ ì„¹ì…˜
if st.session_state.delay_enabled:
    st.markdown("---")
    st.markdown("### ğŸ§ª ì§€ì—° í…ŒìŠ¤íŠ¸ ë„êµ¬")
    
    # ì§€ì—° í•¨ìˆ˜ ë²¤ì¹˜ë§ˆí¬
    with st.expander("âš¡ ì§€ì—° í•¨ìˆ˜ ë²¤ì¹˜ë§ˆí¬", expanded=False):
        st.markdown("ê° ì§€ì—° ë°©ë²•ì˜ ì‹¤ì œ ì„±ëŠ¥ì„ í…ŒìŠ¤íŠ¸í•´ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            test_duration = st.slider(
                "í…ŒìŠ¤íŠ¸ ì‹œê°„ (ì´ˆ)",
                min_value=0.5,
                max_value=5.0,
                value=1.0,
                step=0.5,
                key="benchmark_duration"
            )
        
        with col2:
            test_method = st.selectbox(
                "í…ŒìŠ¤íŠ¸í•  ë°©ë²•",
                options=list(DELAY_FUNCTIONS.keys()),
                format_func=lambda x: DELAY_FUNCTIONS[x][0],
                key="benchmark_method"
            )
        
        with col3:
            if st.button("ğŸƒâ€â™‚ï¸ ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰", key="run_benchmark"):
                _, delay_func = DELAY_FUNCTIONS[test_method]
                
                with st.spinner(f"ğŸ§ª {DELAY_FUNCTIONS[test_method][0]} í…ŒìŠ¤íŠ¸ ì¤‘..."):
                    benchmark_start = time.time()
                    
                    try:
                        delay_func(test_duration)
                        actual_time = time.time() - benchmark_start
                        
                        st.success(f"âœ… í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
                        
                        col_a, col_b, col_c = st.columns(3)
                        with col_a:
                            st.metric("ì˜ˆìƒ ì‹œê°„", f"{test_duration:.2f}ì´ˆ")
                        with col_b:
                            st.metric("ì‹¤ì œ ì‹œê°„", f"{actual_time:.2f}ì´ˆ")
                        with col_c:
                            accuracy = (test_duration / actual_time) * 100
                            st.metric("ì •í™•ë„", f"{accuracy:.1f}%")
                        
                        if accuracy < 90:
                            st.warning(f"âš ï¸ ì •í™•ë„ê°€ ë‚®ìŠµë‹ˆë‹¤. ì‹œìŠ¤í…œ ë¶€í•˜ë‚˜ ê¸°íƒ€ ìš”ì¸ì´ ì˜í–¥ì„ ì£¼ì—ˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
                        elif accuracy > 98:
                            st.success(f"ğŸ¯ ë§¤ìš° ì •í™•í•œ ì§€ì—°ì´ ë‹¬ì„±ë˜ì—ˆìŠµë‹ˆë‹¤!")
                        
                    except Exception as e:
                        actual_time = time.time() - benchmark_start
                        st.error(f"âŒ í…ŒìŠ¤íŠ¸ ì¤‘ ì˜¤ë¥˜: {str(e)}")
                        st.info(f"ê²½ê³¼ ì‹œê°„: {actual_time:.2f}ì´ˆ")

# ğŸ“ˆ ì„±ëŠ¥ ë¶„ì„ ë° ëª¨ë‹ˆí„°ë§ ê°€ì´ë“œ
st.markdown("---")
st.markdown("### ğŸ“ˆ ì„±ëŠ¥ ë¶„ì„ ê°€ì´ë“œ")

with st.expander("ğŸ¯ ì´ ë„êµ¬ì˜ í™œìš© ë°©ë²•", expanded=False):
    st.markdown("""
    ### ğŸ¯ late_levitwo.py í™œìš© ê°€ì´ë“œ
    
    ì´ ë„êµ¬ëŠ” ë‹¤ìŒê³¼ ê°™ì€ ëª©ì ìœ¼ë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:
    
    #### 1. ğŸ“Š New Relic ëª¨ë‹ˆí„°ë§ ê²€ì¦
    - ì˜ë„ì ì¸ ì§€ì—°ì„ í†µí•´ ì„±ëŠ¥ ì´ìŠˆë¥¼ ì‹œë®¬ë ˆì´ì…˜
    - APM ëŒ€ì‹œë³´ë“œì—ì„œ ì‘ë‹µ ì‹œê°„ ì¦ê°€ë¥¼ í™•ì¸
    - ì•Œë¦¼ ë° ì„ê³„ê°’ ì„¤ì •ì˜ ì •í™•ì„± ê²€ì¦
    
    #### 2. ğŸ§ª ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
    - ë‹¤ì–‘í•œ ë¶€í•˜ ì¡°ê±´ì—ì„œì˜ ì‹œìŠ¤í…œ ë™ì‘ í™•ì¸
    - CPU, ë©”ëª¨ë¦¬, I/O ë³‘ëª© ìƒí™© ì‹œë®¬ë ˆì´ì…˜
    - ì‘ë‹µ ì‹œê°„ ë³€í™”ì— ë”°ë¥¸ ì‚¬ìš©ì ê²½í—˜ í‰ê°€
    
    #### 3. ğŸ”§ ì‹œìŠ¤í…œ íŠœë‹
    - íƒ€ì„ì•„ì›ƒ ì„¤ì •ì˜ ì ì ˆì„± í™•ì¸
    - ìºì‹± ì „ëµì˜ íš¨ê³¼ ì¸¡ì •
    - ë¦¬ì†ŒìŠ¤ í• ë‹¹ ìµœì í™”
    
    #### 4. ğŸ“š êµìœ¡ ë° ë°ëª¨
    - ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ì˜ ì¤‘ìš”ì„± ì„¤ëª…
    - ë‹¤ì–‘í•œ ì§€ì—° íŒ¨í„´ì˜ ì˜í–¥ ì‹œì—°
    - ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ë„êµ¬ ì‚¬ìš©ë²• êµìœ¡
    
    #### ì¶”ì²œ í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤:
    
    **ì‹œë‚˜ë¦¬ì˜¤ 1: ê°„ë‹¨í•œ ì‘ë‹µ ì‹œê°„ í…ŒìŠ¤íŠ¸**
    - ì§€ì—° ë°©ë²•: ë‹¨ìˆœ Sleep
    - ì§€ì—° ì‹œê°„: 1-3ì´ˆ
    - ì ìš© ì‹œì : LLM í˜¸ì¶œ ì „
    
    **ì‹œë‚˜ë¦¬ì˜¤ 2: CPU ë¶€í•˜ í…ŒìŠ¤íŠ¸**
    - ì§€ì—° ë°©ë²•: CPU ì§‘ì•½ì 
    - ì§€ì—° ì‹œê°„: 2-5ì´ˆ  
    - ì ìš© ì‹œì : LLM í˜¸ì¶œ ì „ + ì‘ë‹µ í›„
    
    **ì‹œë‚˜ë¦¬ì˜¤ 3: ë³µí•© ë¶€í•˜ í…ŒìŠ¤íŠ¸**
    - ì§€ì—° ë°©ë²•: í˜¼í•© ë°©ë²•
    - ì§€ì—° ì‹œê°„: 3-7ì´ˆ
    - ì ìš© ì‹œì : LLM í˜¸ì¶œ ì „
    
    ê° ì‹œë‚˜ë¦¬ì˜¤ í›„ New Relic ëŒ€ì‹œë³´ë“œì—ì„œ ë‹¤ìŒì„ í™•ì¸í•˜ì„¸ìš”:
    - ì‘ë‹µ ì‹œê°„ ì§€í‘œì˜ ë³€í™”
    - ì²˜ë¦¬ëŸ‰(Throughput) ë³€í™”
    - ì—ëŸ¬ìœ¨ ë³€í™”
    - ì¸í”„ë¼ ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ë¥ 
    """)

with st.expander("ğŸ”— ê´€ë ¨ New Relic ì¿¼ë¦¬", expanded=False):
    st.markdown("""
    ### New Relicì—ì„œ ì§€ì—° í…ŒìŠ¤íŠ¸ ê²°ê³¼ë¥¼ ë¶„ì„í•˜ê¸° ìœ„í•œ NRQL ì¿¼ë¦¬:
    
    **1. ì‘ë‹µ ì‹œê°„ ë¶„í¬ í™•ì¸:**
    ```nrql
    FROM Transaction SELECT histogram(duration) 
    WHERE appName = 'gen-ai-bedrock-late' 
    SINCE 1 hour ago
    ```
    
    **2. ì§€ì—° êµ¬ê°„ë³„ ìš”ì²­ ìˆ˜:**
    ```nrql
    FROM Transaction SELECT count(*) 
    WHERE appName = 'gen-ai-bedrock-late' 
    FACET buckets(duration, 1, 10, 5)
    SINCE 1 hour ago
    ```
    
    **3. LLM í˜¸ì¶œ ì„±ëŠ¥ ë¶„ì„:**
    ```nrql
    FROM LlmCompletion SELECT 
    average(duration), max(duration), min(duration), percentile(duration, 50, 95, 99)
    WHERE appName = 'gen-ai-bedrock-late'
    SINCE 1 hour ago
    ```
    
    **4. ì‹œê°„ëŒ€ë³„ ì„±ëŠ¥ ë³€í™”:**
    ```nrql
    FROM Transaction SELECT average(duration) 
    WHERE appName = 'gen-ai-bedrock-late'
    TIMESERIES 5 minutes SINCE 1 hour ago
    ```
    
    **5. ì—ëŸ¬ìœ¨ ëª¨ë‹ˆí„°ë§:**
    ```nrql
    FROM Transaction SELECT percentage(count(*), WHERE error IS true)
    WHERE appName = 'gen-ai-bedrock-late'
    SINCE 1 hour ago
    ```
    """)

# í‘¸í„°
st.markdown("---")
st.markdown("ğŸŒ nr-bedrock-observability-python v2.4.1 - ìë™ íŒ¨ì¹˜ ëª¨ë“œ + ì§€ì—° ì‹œë®¬ë ˆì´ì…˜")
st.caption("ì´ ë„êµ¬ëŠ” ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ë° ëª¨ë‹ˆí„°ë§ ê²€ì¦ ëª©ì ìœ¼ë¡œ ì œì‘ë˜ì—ˆìŠµë‹ˆë‹¤. í”„ë¡œë•ì…˜ í™˜ê²½ì—ì„œëŠ” ì§€ì—° ê¸°ëŠ¥ì„ ë¹„í™œì„±í™”í•˜ì„¸ìš”.") 