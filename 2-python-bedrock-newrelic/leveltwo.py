"""
Streamlit + Bedrock + New Relic ëª¨ë‹ˆí„°ë§ ì˜ˆì œ

ëª¨ë“  boto3.client('bedrock-runtime') í˜¸ì¶œì´ ìë™ìœ¼ë¡œ ëª¨ë‹ˆí„°ë§ë©ë‹ˆë‹¤.
"""

import streamlit as st
import boto3
import json
import time
import uuid

# ìƒìˆ˜ (ë¼ì´ë¸ŒëŸ¬ë¦¬ import ì „ì— ì •ì˜)
REGION = "us-west-2"
MODEL_ID = "anthropic.claude-3-sonnet-20240229-v1:0"
APP_NAME = "gen-ai-bedrock"

# New Relic ì—ì´ì „íŠ¸ ì´ˆê¸°í™” - ì„¤ì • íŒŒì¼ ëª…ì‹œì  ì§€ì •
import newrelic.agent
try:
    newrelic.agent.initialize('newrelic.ini')
    print("âœ… New Relic ì—ì´ì „íŠ¸ ì´ˆê¸°í™” ì„±ê³µ")
except Exception as e:
    print(f"âš ï¸ New Relic ì—ì´ì „íŠ¸ ì´ˆê¸°í™” ì˜¤ë¥˜: {e}")
    # fallback: í™˜ê²½ë³€ìˆ˜ë§Œìœ¼ë¡œ ì´ˆê¸°í™” ì‹œë„
    newrelic.agent.initialize()

# import nr_bedrock_observability ë° ì¦‰ì‹œ auto patch í™œì„±í™”
import nr_bedrock_observability
nr_bedrock_observability.enable_auto_patch(application_name=APP_NAME)

from nr_bedrock_observability import (
    create_streamlit_evaluation_ui,
    create_streamlit_nrql_queries,
    get_streamlit_session_info,
    get_sample_nrql_queries
)

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="Bedrock + New Relic", 
    page_icon="ğŸ¤–",
    layout="wide"
)

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "messages" not in st.session_state:
    st.session_state.messages = []
if "user_role_prompt" not in st.session_state:
    st.session_state.user_role_prompt = "ë‹¹ì‹ ì€ ë„ì›€ì´ ë˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤."
if "user_system_prompt" not in st.session_state:
    st.session_state.user_system_prompt = "ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëª…í™•í•˜ê³  ì •í™•í•˜ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”. í•œêµ­ì–´ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”."
if "user_temperature" not in st.session_state:
    st.session_state.user_temperature = 0.7
if "user_top_p" not in st.session_state:
    st.session_state.user_top_p = 0.9
if "last_response_data" not in st.session_state:
    st.session_state.last_response_data = {}

# ì¶”ê°€ ì„¸ì…˜ ìƒíƒœ (ëª¨ë‹ˆí„°ë§ìš©)
if "trace_id" not in st.session_state:
    st.session_state.trace_id = str(uuid.uuid4())
if "conversation_id" not in st.session_state:
    st.session_state.conversation_id = str(uuid.uuid4())
if "current_completion_id" not in st.session_state:
    st.session_state.current_completion_id = None
if "current_system_prompt" not in st.session_state:
    st.session_state.current_system_prompt = None
if "raw_result" not in st.session_state:
    st.session_state.raw_result = {}
if "message_count" not in st.session_state:
    st.session_state.message_count = 0


@st.cache_resource
def get_bedrock_client():
    """ìë™ íŒ¨ì¹˜ê°€ ì ìš©ëœ Bedrock í´ë¼ì´ì–¸íŠ¸ ìƒì„±"""
    client = boto3.client('bedrock-runtime', region_name=REGION)
    
    return client

# UI êµ¬ì„± í•¨ìˆ˜
def build_ui():
    """Streamlit UI êµ¬ì„±"""
    st.title("ğŸ¤– AWS Bedrock ì§ì ‘ í˜¸ì¶œ Q&A + ëª¨ë‹ˆí„°ë§")
    
    # ë ˆì´ì•„ì›ƒ: ë©”ì¸ ì»¬ëŸ¼ê³¼ ì‚¬ì´ë“œë°”
    main_col, info_col = st.columns([2, 1])
    
    with info_col:
        st.header("ì•± ì •ë³´")
        st.markdown(f"""
        **ëª¨ë¸**: {MODEL_ID}
        
        **Knowledge Base**: ì‚¬ìš© ì•ˆí•¨ (ì§ì ‘ í˜¸ì¶œ)
        
        **ë¦¬ì „**: {REGION}
        
        **NewRelic ì•± ì´ë¦„**: {APP_NAME}
        """)
        
        # ê¸°ë³¸ ì„¤ì • ë³µì› ë²„íŠ¼
        if st.button("ğŸ”„ ê¸°ë³¸ ì„¤ì • ë³µì›", help="ëª¨ë“  ì„¤ì •ì„ ê¸°ë³¸ê°’ìœ¼ë¡œ ë˜ëŒë¦½ë‹ˆë‹¤"):
            st.session_state.user_role_prompt = "ë‹¹ì‹ ì€ ë„ì›€ì´ ë˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤."
            st.session_state.user_system_prompt = "ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëª…í™•í•˜ê³  ì •í™•í•˜ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”. í•œêµ­ì–´ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”."
            st.session_state.user_temperature = 0.3
            st.session_state.user_top_p = 0.9
            st.rerun()
        
        st.markdown("---")  # êµ¬ë¶„ì„  ì¶”ê°€
        
        # Role Prompt ì…ë ¥
        st.subheader("Role Prompt")
        new_role_prompt = st.text_area(
            "ëª¨ë¸ì˜ ì—­í• ì„ ì •ì˜í•˜ì„¸ìš”:",
            value=st.session_state.user_role_prompt,
            height=80,
            key="role_prompt_input",
            help="ì˜ˆ: 'ë‹¹ì‹ ì€ ì˜ë£Œ ì „ë¬¸ê°€ì…ë‹ˆë‹¤', 'ë‹¹ì‹ ì€ ì½”ë”© íŠœí„°ì…ë‹ˆë‹¤' ë“±"
        )
        if new_role_prompt != st.session_state.user_role_prompt:
            st.session_state.user_role_prompt = new_role_prompt
        
        # System Prompt ì…ë ¥
        st.subheader("System Prompt")
        new_system_prompt = st.text_area(
            "êµ¬ì²´ì ì¸ í–‰ë™ ì§€ì¹¨ì„ ì…ë ¥í•˜ì„¸ìš”:",
            value=st.session_state.user_system_prompt,
            height=100,
            key="system_prompt_input",
            help="ëª¨ë¸ì´ ì–´ë–»ê²Œ í–‰ë™í•´ì•¼ í•˜ëŠ”ì§€ êµ¬ì²´ì ìœ¼ë¡œ ëª…ì‹œí•˜ì„¸ìš”"
        )
        if new_system_prompt != st.session_state.user_system_prompt:
            st.session_state.user_system_prompt = new_system_prompt
        
        # Temperature ìŠ¬ë¼ì´ë”
        st.subheader("Temperature")
        new_temperature = st.slider(
            "ì°½ì˜ì„± ìˆ˜ì¤€ (ë‚®ì„ìˆ˜ë¡ ì¼ê´€ì„± ë†’ìŒ)",
            min_value=0.0,
            max_value=1.0,
            value=st.session_state.user_temperature,
            step=0.1,
            key="temperature_slider",
            help="0.0: ë§¤ìš° ì¼ê´€ì , 1.0: ë§¤ìš° ì°½ì˜ì "
        )
        if new_temperature != st.session_state.user_temperature:
            st.session_state.user_temperature = new_temperature
        
        # Top-p ìŠ¬ë¼ì´ë”
        st.subheader("Top-p (Nucleus Sampling)")
        new_top_p = st.slider(
            "ì‘ë‹µ ë‹¤ì–‘ì„± ì œì–´",
            min_value=0.0,
            max_value=1.0,
            value=st.session_state.user_top_p,
            step=0.1,
            key="top_p_slider",
            help="0.0: ê°€ì¥ í™•ë¥  ë†’ì€ ë‹¨ì–´ë§Œ, 1.0: ëª¨ë“  ë‹¨ì–´ ê³ ë ¤"
        )
        if new_top_p != st.session_state.user_top_p:
            st.session_state.user_top_p = new_top_p
            
        # í˜„ì¬ ì„¤ì • ë¯¸ë¦¬ë³´ê¸°
        with st.expander("í˜„ì¬ íŒŒë¼ë¯¸í„° ì„¤ì •", expanded=False):
            st.markdown("**ìµœì¢… System Prompt:**")
            combined_preview = f"{st.session_state.user_role_prompt}\n\n{st.session_state.user_system_prompt}"
            st.code(combined_preview)
            st.markdown(f"**Temperature:** {st.session_state.user_temperature}")
            st.markdown(f"**Top-p:** {st.session_state.user_top_p}")
        
        # íŠ¸ë ˆì´ìŠ¤ ì •ë³´
        st.subheader("íŠ¸ë ˆì´ìŠ¤ ì •ë³´")
        
        # ID ì„¤ëª… ì¶”ê°€
        with st.expander("ID ì„¤ëª…", expanded=True):
            st.markdown("""
            **ëŒ€í™” ID (Conversation ID)**: ì‚¬ìš©ìì˜ ì „ì²´ ëŒ€í™” ì„¸ì…˜ì„ ì‹ë³„í•˜ëŠ” ê³ ìœ  IDì…ë‹ˆë‹¤. ìƒˆë¡œìš´ ëŒ€í™” ì„¸ì…˜ì´ ì‹œì‘ë  ë•Œ ìƒì„±ë˜ë©°, ì‚¬ìš©ìê°€ ì—¬ëŸ¬ ë©”ì‹œì§€ë¥¼ ì£¼ê³ ë°›ëŠ” ë™ì•ˆ ë™ì¼í•˜ê²Œ ìœ ì§€ë©ë‹ˆë‹¤. ì „ì²´ ëŒ€í™” íë¦„ì„ ì¶”ì í•  ë•Œ ì‚¬ìš©ë©ë‹ˆë‹¤.
            
            **íŠ¸ë ˆì´ìŠ¤ ID (Trace ID)**: ê° ë©”ì‹œì§€ êµí™˜ì„ ì¶”ì í•˜ê¸° ìœ„í•œ IDì…ë‹ˆë‹¤. ìƒˆë¡œìš´ ì‚¬ìš©ì ì…ë ¥ì´ ìˆì„ ë•Œë§ˆë‹¤ ìƒˆë¡œìš´ íŠ¸ë ˆì´ìŠ¤ IDê°€ ìƒì„±ë©ë‹ˆë‹¤. ë‹¨ì¼ ìš”ì²­ì˜ ì „ì²´ ì²˜ë¦¬ ê³¼ì •(Bedrock ì§ì ‘ í˜¸ì¶œ)ì„ ì¶”ì í•˜ëŠ” ë° ì‚¬ìš©ë©ë‹ˆë‹¤.
            
            **ì™„ì„± ID (Completion ID)**: LLM ì‘ë‹µ ì™„ì„±ì— ëŒ€í•œ ê³ ìœ  IDì…ë‹ˆë‹¤. Bedrock API í˜¸ì¶œì˜ ê²°ê³¼ë¥¼ ì‹ë³„í•˜ê³  ì¶”ì í•˜ëŠ” ë° ì‚¬ìš©ë©ë‹ˆë‹¤. ê° ì™„ì„±ì€ íŠ¹ì • ì‚¬ìš©ì ì§ˆë¬¸ì— ëŒ€í•œ ëª¨ë¸ì˜ ì‘ë‹µì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.
            """)
        
        st.code(f"ëŒ€í™” ID: {st.session_state.conversation_id}")
        st.code(f"íŠ¸ë ˆì´ìŠ¤ ID: {st.session_state.trace_id}")
        if st.session_state.current_completion_id:
            st.code(f"ì™„ì„± ID: {st.session_state.current_completion_id}")
            
            # ëª¨ë¸ í‰ê°€ ë¶„ì„ NRQL ì˜ˆì‹œ ì¶”ê°€
            with st.expander("ëª¨ë¸ í‰ê°€ ë¶„ì„ ì¿¼ë¦¬", expanded=False):
                st.markdown("### ëª¨ë¸ í‰ê°€ ë°ì´í„° ë¶„ì„ì„ ìœ„í•œ NRQL ì¿¼ë¦¬")
                
                # ë¼ì´ë¸ŒëŸ¬ë¦¬ í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ìƒ˜í”Œ ì¿¼ë¦¬ ê°€ì ¸ì˜¤ê¸° (Knowledge Base ID ì—†ì´)
                sample_queries = get_sample_nrql_queries(
                    trace_id=st.session_state.trace_id,
                    completion_id=st.session_state.current_completion_id,
                    conversation_id=st.session_state.conversation_id,
                    kb_id=None  # Knowledge Base ì—†ìŒ
                )
                
                # ì¿¼ë¦¬ ê²°ê³¼ê°€ ì—†ëŠ” ì´ìœ ì— ëŒ€í•œ ì„¤ëª… ì¶”ê°€
                st.warning("""
                **ì°¸ê³ **: ì¿¼ë¦¬ ê²°ê³¼ê°€ ì—†ëŠ” ê²½ìš° ë‹¤ìŒê³¼ ê°™ì€ ì´ìœ ê°€ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤:
                
                1. ì•„ì§ í‰ê°€ ë°ì´í„°ê°€ ìˆ˜ì§‘ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë¨¼ì € ëª‡ ê°œì˜ ëª¨ë¸ í‰ê°€ë¥¼ ì œì¶œí•´ë³´ì„¸ìš”.
                2. ì´ë²¤íŠ¸ íƒ€ì… ì´ë¦„ì´ ì‹¤ì œ New Relicì— ê¸°ë¡ëœ ì´ë¦„ê³¼ ë‹¤ë¥¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
                3. New Relic ê³„ì • ì„¤ì •ì—ì„œ ì‚¬ìš©ì ì •ì˜ ì´ë²¤íŠ¸ ìˆ˜ì§‘ì´ í™œì„±í™”ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.
                4. ì‹œê°„ ë²”ìœ„ë¥¼ ë” ë„“ê²Œ ì„¤ì •í•˜ì—¬ í™•ì¸í•´ ë³´ì„¸ìš”.
                
                í‰ê°€ ì œì¶œ í›„ ë°ì´í„°ê°€ New Relicì— í‘œì‹œë˜ëŠ” ë° ì•½ê°„ì˜ ì‹œê°„ì´ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
                """)
                
                # ìƒ˜í”Œ ì¿¼ë¦¬ í‘œì‹œ
                for title, query in sample_queries.items():
                    st.markdown(f"**{title}:**")
                    st.code(query)
        
        # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ í‘œì‹œ
        if st.session_state.current_system_prompt:
            with st.expander("ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸", expanded=False):
                st.code(st.session_state.current_system_prompt)
        
        # Knowledge Base ê²€ìƒ‰ ê²°ê³¼ëŠ” í‘œì‹œí•˜ì§€ ì•ŠìŒ (ê²€ìƒ‰ ì•ˆí•¨)
        # if st.session_state.current_search_results:
        #     with st.expander("ê²€ìƒ‰ ê²°ê³¼", expanded=False):
        #         ...
        
        # ì‹¤í–‰ ì •ë³´ í‘œì‹œ
        if st.session_state.raw_result:
            with st.expander("ì‹¤í–‰ ì •ë³´", expanded=False):
                # st.metric("ê²€ìƒ‰ ì‹œê°„", f"{st.session_state.raw_result.get('search_time_ms', 0)} ms")
                st.metric("LLM ì‘ë‹µ ì‹œê°„", f"{st.session_state.raw_result.get('llm_time_ms', 0)} ms")
                st.metric("ì´ ì²˜ë¦¬ ì‹œê°„", f"{st.session_state.raw_result.get('total_time_ms', 0)} ms")
                st.metric("í† í° ìˆ˜", st.session_state.raw_result.get('token_count', 0))
                
                # ì‚¬ìš©ëœ íŒŒë¼ë¯¸í„° ì •ë³´ ì¶”ê°€
                st.markdown("**ì‚¬ìš©ëœ íŒŒë¼ë¯¸í„°:**")
                st.markdown(f"- Temperature: {st.session_state.raw_result.get('temperature', 'N/A')}")
                st.markdown(f"- Top-p: {st.session_state.raw_result.get('top_p', 'N/A')}")
                st.markdown(f"- ì´ í† í°: {st.session_state.raw_result.get('total_tokens', 'N/A')}")
                st.markdown(f"- í”„ë¡¬í”„íŠ¸ í† í°: {st.session_state.raw_result.get('prompt_tokens', 'N/A')}")
        
        # ìƒˆ ëŒ€í™” ì‹œì‘ ë²„íŠ¼
        if st.button("ìƒˆ ëŒ€í™” ì‹œì‘"):
            # ì´ì „ í‰ê°€ ìƒíƒœ í‚¤ë¥¼ ëª¨ë‘ ì°¾ì•„ì„œ ì´ˆê¸°í™”
            eval_keys = [key for key in st.session_state.keys() if key.startswith("eval_")]
            for key in eval_keys:
                del st.session_state[key]
                
            # ì´ì „ ìŠ¬ë¼ì´ë”/ìœ„ì ¯ í‚¤ ì´ˆê¸°í™”
            widget_keys = [key for key in st.session_state.keys() if 
                          any(key.startswith(prefix) for prefix in 
                              ["overall_score_", "relevance_score_", "accuracy_score_", 
                               "completeness_score_", "coherence_score_", "helpfulness_score_",
                               "response_time_score_", "query_type_", "domain_", "feedback_comment_",
                               "submit_", "reset_log_", "test_eval_"])]
            for key in widget_keys:
                if key in st.session_state:
                    del st.session_state[key]
            
            # ê¸°ë³¸ ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
            st.session_state.trace_id = str(uuid.uuid4())
            st.session_state.conversation_id = str(uuid.uuid4())
            st.session_state.messages = []
            st.session_state.current_completion_id = None
            st.session_state.raw_result = {}
            # st.session_state.current_search_results = []  # Knowledge Base ì—†ìœ¼ë‹ˆ ì‚¬ìš© ì•ˆí•¨
            # í˜„ì¬ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ë¥¼ ì‚¬ìš©ì ì„¤ì •ìœ¼ë¡œ ì—…ë°ì´íŠ¸
            st.session_state.current_system_prompt = f"{st.session_state.user_role_prompt}\n\n{st.session_state.user_system_prompt}"
            st.session_state.message_count = 0
            st.rerun()
    
    return main_col, info_col

# UI êµ¬ì„±
st.title("ğŸ¤– Auto Bedrock + New Relic")
st.caption("nr-bedrock-observability-python v2.4.1 - ìë™ íŒ¨ì¹˜ ëª¨ë“œ")

# ğŸ”„ ì•± ì‹œì‘ ì‹œ ëª¨ë‹ˆí„°ë§ ì´ˆê¸°í™” ìƒíƒœ í™•ì¸
with st.container():
    col1, col2 = st.columns([3, 1])
    with col1:
        # Bedrock í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” (ìºì‹œë¨, warm-up í¬í•¨)
        _ = get_bedrock_client()
    with col2:
        # New Relic ì—ì´ì „íŠ¸ ìƒíƒœ í™•ì¸
        try:
            app = newrelic.agent.application()
            if app and app.name:
                st.success(f"âœ… NR Agent: {app.name}")
            else:
                st.warning("âš ï¸ NR Agent: ë¯¸ì´ˆê¸°í™”")
        except:
            st.error("âŒ NR Agent: ì˜¤ë¥˜")

# ë©”ì¸ ë ˆì´ì•„ì›ƒ
main_col, sidebar_col = st.columns([2, 1])

with sidebar_col:
    st.header("âš™ï¸ ì„¤ì •")
    
    # ëª¨ë¸ íŒŒë¼ë¯¸í„° ì„¤ì •
    st.header("ëª¨ë¸ íŒŒë¼ë¯¸í„° ì„¤ì •")
    
    # í”„ë¦¬ì…‹ ë²„íŠ¼ë“¤
    st.subheader("ë¹ ë¥¸ ì„¤ì • í”„ë¦¬ì…‹")
    col1, col2, col3 = st.columns(3)
    
    with col1:
        if st.button("ğŸ¥ ì˜ë£Œ ì „ë¬¸ê°€", help="ì˜ë£Œ ê´€ë ¨ ì§ˆë¬¸ì— íŠ¹í™”ëœ ì„¤ì •"):
            st.session_state.user_role_prompt = "ë‹¹ì‹ ì€ 15ë…„ ê²½ë ¥ì˜ ì„ìƒ ì˜ì‚¬ì´ì ë‚´ê³¼ ì „ë¬¸ì˜ì…ë‹ˆë‹¤. í™˜ìë“¤ì—ê²Œ ì‹¤ìš©ì ì´ê³  êµ¬ì²´ì ì¸ ì˜í•™ì  ì¡°ì–¸ì„ ì œê³µí•˜ëŠ” ê²ƒì´ ë‹¹ì‹ ì˜ ì „ë¬¸ ë¶„ì•¼ì…ë‹ˆë‹¤."
            st.session_state.user_system_prompt = """ë‹¤ìŒ ì›ì¹™ì— ë”°ë¼ ì˜í•™ì  ì¡°ì–¸ì„ ì œê³µí•˜ì„¸ìš”:

1. **ì „ë¬¸ì  ì§„ë‹¨ê³¼ ì¹˜ë£Œ ê¶Œê³ **: ì¦ìƒì„ ë¶„ì„í•˜ê³  ê°€ëŠ¥í•œ ì›ì¸ì„ ì œì‹œí•˜ë©°, ì¼ë°˜ì˜ì•½í’ˆì´ë‚˜ ìƒí™œìŠµê´€ ê°œì„  ë“± êµ¬ì²´ì ì¸ í•´ê²°ì±…ì„ ì œì•ˆí•˜ì„¸ìš”.

2. **ë‹¨ê³„ë³„ ì¹˜ë£Œ ì ‘ê·¼**: ê²½ì¦ì˜ ê²½ìš° ìê°€ ê´€ë¦¬ ë°©ë²•ë¶€í„° ì‹œì‘í•˜ì—¬, í•„ìš”ì‹œ ì „ë¬¸ì˜ ì§„ë£Œë¥¼ ê¶Œí•˜ëŠ” ë‹¨ê³„ì  ì ‘ê·¼ë²•ì„ ì‚¬ìš©í•˜ì„¸ìš”.

3. **ì‹¤ìš©ì  ì•½ë¬¼ ì •ë³´**: ì¼ë°˜ì˜ì•½í’ˆì˜ ê²½ìš° êµ¬ì²´ì ì¸ ì„±ë¶„ëª…, ìš©ë²•Â·ìš©ëŸ‰, ì£¼ì˜ì‚¬í•­ì„ ëª…í™•íˆ ì œì‹œí•˜ì„¸ìš”.

4. **ìœ„í—˜ ì‹ í˜¸ ì¸ì‹**: ì‘ê¸‰ ìƒí™©ì´ë‚˜ ì „ë¬¸ì˜ ì§„ë£Œê°€ ë°˜ë“œì‹œ í•„ìš”í•œ ê²½ìš°ë¥¼ ëª…í™•íˆ êµ¬ë¶„í•˜ì—¬ ì•ˆë‚´í•˜ì„¸ìš”.

5. **ê°œì¸í™”ëœ ì¡°ì–¸**: ì—°ë ¹, ê¸°ì¡´ ì§ˆí™˜, ë³µìš© ì¤‘ì¸ ì•½ë¬¼ ë“±ì„ ê³ ë ¤í•œ ë§ì¶¤í˜• ì¡°ì–¸ì„ ì œê³µí•˜ì„¸ìš”.

í•­ìƒ ì˜í•™ì  ê·¼ê±°ë¥¼ ë°”íƒ•ìœ¼ë¡œ í•˜ë˜, í™˜ìê°€ ì‹¤ì œë¡œ í™œìš©í•  ìˆ˜ ìˆëŠ” êµ¬ì²´ì ì´ê³  ì‹¤ìš©ì ì¸ ì •ë³´ë¥¼ ìš°ì„  ì œê³µí•˜ì„¸ìš”. í•œêµ­ì–´ë¡œ ëª…í™•í•˜ê³  ì´í•´í•˜ê¸° ì‰½ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”."""
            st.session_state.user_temperature = 0.2
            st.session_state.user_top_p = 0.8
            st.rerun()
    
    with col2:
        if st.button("ğŸ’» ì½”ë”© íŠœí„°", help="í”„ë¡œê·¸ë˜ë° í•™ìŠµì— íŠ¹í™”ëœ ì„¤ì •"):
            st.session_state.user_role_prompt = "ë‹¹ì‹ ì€ 10ë…„ ì´ìƒì˜ ì‹¤ë¬´ ê²½í—˜ì„ ê°€ì§„ ì‹œë‹ˆì–´ ê°œë°œìì´ì í”„ë¡œê·¸ë˜ë° êµìœ¡ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹¤ì–‘í•œ í”„ë¡œê·¸ë˜ë° ì–¸ì–´ì™€ í”„ë ˆì„ì›Œí¬ì— ëŠ¥í†µí•˜ë©°, ë³µì¡í•œ ê°œë…ì„ ì‰½ê²Œ ì„¤ëª…í•˜ëŠ” ê²ƒì´ íŠ¹ê¸°ì…ë‹ˆë‹¤."
            st.session_state.user_system_prompt = """ë‹¤ìŒ êµìœ¡ ë°©ë²•ë¡ ì— ë”°ë¼ í”„ë¡œê·¸ë˜ë° ì§€ë„ë¥¼ í•´ì£¼ì„¸ìš”:

1. **ë‹¨ê³„ë³„ í•™ìŠµ ì ‘ê·¼**:
   - ê°œë… ì„¤ëª… â†’ ê°„ë‹¨í•œ ì˜ˆì œ â†’ ì‹¤ìŠµ ë¬¸ì œ â†’ ì‹¬í™” ì‘ìš© ìˆœì„œë¡œ ì§„í–‰
   - í•™ìŠµìì˜ ìˆ˜ì¤€ì— ë§ëŠ” ì ì ˆí•œ ë‚œì´ë„ ì¡°ì ˆ

2. **ì‹¤ìŠµ ì¤‘ì‹¬ êµìœ¡**:
   - ëª¨ë“  ê°œë…ì— ëŒ€í•´ ì‹¤í–‰ ê°€ëŠ¥í•œ ì½”ë“œ ì˜ˆì œ ì œê³µ
   - ì£¼ì„ì„ ìƒì„¸íˆ ë‹¬ì•„ ì½”ë“œì˜ ê° ë¶€ë¶„ ì„¤ëª…
   - ì‹¤ì œ í”„ë¡œì íŠ¸ì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ì‹¤ìš©ì ì¸ ì˜ˆì œ ìš°ì„ 

3. **ë””ë²„ê¹…ê³¼ ë¬¸ì œ í•´ê²°**:
   - ìì£¼ ë°œìƒí•˜ëŠ” ì˜¤ë¥˜ì™€ í•´ê²° ë°©ë²• ì„¤ëª…
   - ì½”ë“œ ë¦¬ë·° ê´€ì ì—ì„œ ê°œì„ ì  ì œì‹œ
   - íš¨ìœ¨ì ì¸ ë””ë²„ê¹… ë°©ë²• ì•ˆë‚´

4. **ëª¨ë²” ì‚¬ë¡€ì™€ ì½”ë”© í‘œì¤€**:
   - í´ë¦° ì½”ë“œ ì‘ì„± ì›ì¹™ ì ìš©
   - ì—…ê³„ í‘œì¤€ê³¼ ëª¨ë²” ì‚¬ë¡€ ì†Œê°œ
   - ì„±ëŠ¥ ìµœì í™”ì™€ ìœ ì§€ë³´ìˆ˜ì„± ê³ ë ¤

5. **í•™ìŠµ ë™ê¸° ë¶€ì—¬**:
   - ì‹¤ë¬´ì—ì„œì˜ í™œìš© ì‚¬ë¡€ ì œì‹œ
   - ë‹¨ê³„ë³„ ì„±ì·¨ê° ì œê³µ
   - ì¶”ê°€ í•™ìŠµ ìë£Œì™€ ë°œì „ ë°©í–¥ ì œì•ˆ

í•­ìƒ 'ì™œ ì´ë ‡ê²Œ ì‘ì„±í•˜ëŠ”ê°€?'ì— ëŒ€í•œ ì´ìœ ë¥¼ ì„¤ëª…í•˜ê³ , ëŒ€ì•ˆì  ì ‘ê·¼ë²•ë„ í•¨ê»˜ ì œì‹œí•˜ì„¸ìš”. í•œêµ­ì–´ë¡œ ì¹œê·¼í•˜ê³  ì´í•´í•˜ê¸° ì‰½ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”."""
            st.session_state.user_temperature = 0.4
            st.session_state.user_top_p = 0.9
            st.rerun()
    
    with col3:
        if st.button("ğŸ¨ ì°½ì˜ì  ì‘ê°€", help="ì°½ì‘ í™œë™ì— íŠ¹í™”ëœ ì„¤ì •"):
            st.session_state.user_role_prompt = "ë‹¹ì‹ ì€ ë² ìŠ¤íŠ¸ì…€ëŸ¬ ì‘í’ˆì„ ì—¬ëŸ¬ í¸ ì¶œê°„í•œ ì „ë¬¸ ì‘ê°€ì´ì ì°½ì‘ ì§€ë„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì†Œì„¤, ì—ì„¸ì´, ì‹œë‚˜ë¦¬ì˜¤ ë“± ë‹¤ì–‘í•œ ì¥ë¥´ì— ëŠ¥í†µí•˜ë©°, ë…ìì˜ ë§ˆìŒì„ ì‚¬ë¡œì¡ëŠ” ìŠ¤í† ë¦¬í…”ë§ì´ íŠ¹ê¸°ì…ë‹ˆë‹¤."
            st.session_state.user_system_prompt = """ë‹¤ìŒ ì°½ì‘ ì›ì¹™ì— ë”°ë¼ ê¸€ì“°ê¸° ì§€ë„ë¥¼ í•´ì£¼ì„¸ìš”:

1. **ì°½ì‘ í”„ë¡œì„¸ìŠ¤ ì•ˆë‚´**:
   - ì•„ì´ë””ì–´ ë°œêµ´ â†’ êµ¬ì„± ê³„íš â†’ ì´ˆê³  ì‘ì„± â†’ ìˆ˜ì •/í¸ì§‘ ë‹¨ê³„ë³„ ê°€ì´ë“œ
   - ê° ë‹¨ê³„ì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” êµ¬ì²´ì ì¸ ê¸°ë²•ê³¼ ë„êµ¬ ì œì‹œ

2. **ìŠ¤í† ë¦¬í…”ë§ êµ¬ì¡°**:
   - ë§¤ë ¥ì ì¸ ë„ì…ë¶€, ê¸´ì¥ê° ìˆëŠ” ì „ê°œ, ë§Œì¡±ìŠ¤ëŸ¬ìš´ ê²°ë§ êµ¬ì„±ë²•
   - ìºë¦­í„° ê°œë°œê³¼ ê°ˆë“± êµ¬ì¡° ì„¤ê³„
   - ì¥ë¥´ë³„ íŠ¹ì„±ì„ ê³ ë ¤í•œ ë§ì¶¤í˜• ì¡°ì–¸

3. **ë¬¸ì²´ì™€ í‘œí˜„ë ¥**:
   - ìƒí™©ê³¼ ê°ì •ì— ë§ëŠ” ìƒìƒí•œ ë¬˜ì‚¬ ê¸°ë²•
   - ë…ìì˜ ê³µê°ì„ ì´ëŒì–´ë‚´ëŠ” í‘œí˜„ ë°©ë²•
   - ë¬¸ì¥ ë¦¬ë“¬ê³¼ í˜¸í¡ì„ ê³ ë ¤í•œ ê¸€ì“°ê¸°

4. **ë…ì°½ì„±ê³¼ ì°¨ë³„í™”**:
   - ê¸°ì¡´ ì‘í’ˆê³¼ ì°¨ë³„í™”ë˜ëŠ” ë…íŠ¹í•œ ê´€ì  ì œì‹œ
   - ê°œì¸ì  ê²½í—˜ê³¼ ìƒìƒë ¥ì„ ê²°í•©í•œ ì˜¤ë¦¬ì§€ë„ ì•„ì´ë””ì–´ ê°œë°œ
   - íŠ¸ë Œë“œë¥¼ ë°˜ì˜í•˜ë©´ì„œë„ ì‹œëŒ€ë¥¼ ì´ˆì›”í•˜ëŠ” ë³´í¸ì„± ì¶”êµ¬

5. **ì‹¤ìš©ì  ê¸€ì“°ê¸° ì¡°ì–¸**:
   - ì‘ê°€ì˜ ë¸”ë¡ ê·¹ë³µ ë°©ë²•
   - íš¨ê³¼ì ì¸ ìë£Œ ì¡°ì‚¬ì™€ ì·¨ì¬ ë°©ë²•
   - ì¶œê°„ê³¼ ë…ì ì†Œí†µì„ ìœ„í•œ ì‹¤ë¬´ì  ì¡°ì–¸

í•­ìƒ êµ¬ì²´ì ì¸ ì˜ˆì‹œì™€ í•¨ê»˜ ì„¤ëª…í•˜ê³ , ì°½ì‘ìì˜ ê°œì„±ì„ ì‚´ë¦´ ìˆ˜ ìˆëŠ” ë‹¤ì–‘í•œ ì ‘ê·¼ë²•ì„ ì œì•ˆí•˜ì„¸ìš”. í•œêµ­ì–´ì˜ ì•„ë¦„ë‹¤ì›€ì„ ì‚´ë¦° í’ë¶€í•œ í‘œí˜„ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”."""
            st.session_state.user_temperature = 0.8
            st.session_state.user_top_p = 0.95
            st.rerun()
    
    # Role Prompt
    st.session_state.user_role_prompt = st.text_area(
        "Role Prompt:",
        value=st.session_state.user_role_prompt,
        height=80
    )
    
    # System Prompt  
    st.session_state.user_system_prompt = st.text_area(
        "System Prompt:",
        value=st.session_state.user_system_prompt,
        height=100
    )
    
    # Temperature
    st.session_state.user_temperature = st.slider(
        "Temperature (ì°½ì˜ì„±)",
        0.0, 1.0, 
        st.session_state.user_temperature,
        0.1
    )
    
    # Top-p
    st.session_state.user_top_p = st.slider(
        "Top-p (ë‹¤ì–‘ì„±)",
        0.0, 1.0,
        st.session_state.user_top_p, 
        0.05
    )
    
    # í˜„ì¬ ì„¤ì • í‘œì‹œ
    with st.expander("ğŸ“‹ í˜„ì¬ ì„¤ì •", expanded=False):
        combined_prompt = f"{st.session_state.user_role_prompt}\n\n{st.session_state.user_system_prompt}"
        st.code(combined_prompt)
        st.write(f"Temperature: {st.session_state.user_temperature}")
        st.write(f"Top-p: {st.session_state.user_top_p}")
    
    # ì„¸ì…˜ ì •ë³´ í‘œì‹œ
    st.subheader("ğŸ“Š ì„¸ì…˜ ì •ë³´")
    session_info = get_streamlit_session_info()
    st.code(f"ëŒ€í™” ID: {session_info.get('conversation_id', 'N/A')}")
    st.code(f"ë©”ì‹œì§€ ë²ˆí˜¸: {session_info.get('message_index', 'N/A')}")
    
    # ğŸ› ë””ë²„ê¹…: ëª¨ë‹ˆí„°ë§ ìƒíƒœ í™•ì¸
    st.subheader("ğŸ” ëª¨ë‹ˆí„°ë§ ìƒíƒœ")
    try:
        client = get_bedrock_client()
        is_monitored = hasattr(client.invoke_model, '_nr_monitored')
        is_auto_patched = hasattr(client.invoke_model, '__wrapped__')
        
        st.markdown(f"**ëª¨ë‹ˆí„°ë§ ì ìš©**: {'âœ… ì˜ˆ' if is_monitored else 'âŒ ì•„ë‹ˆì˜¤'}")
        st.markdown(f"**ìë™ íŒ¨ì¹˜**: {'âœ… ì˜ˆ' if is_auto_patched else 'âŒ ì•„ë‹ˆì˜¤'}")
        st.markdown(f"**ì•± ì´ë¦„**: {APP_NAME}")
        
        # boto3 í´ë¼ì´ì–¸íŠ¸ ì •ë³´
        st.code(f"í´ë¼ì´ì–¸íŠ¸ ID: {id(client)}")
        
    except Exception as e:
        st.error(f"ëª¨ë‹ˆí„°ë§ ìƒíƒœ í™•ì¸ ì˜¤ë¥˜: {str(e)}")
    
    # ìƒˆ ëŒ€í™” ì‹œì‘
    if st.button("ğŸ”„ ìƒˆ ëŒ€í™” ì‹œì‘"):
        st.session_state.messages = []
        st.session_state.last_response_data = {}
        # conversation_idëŠ” ìë™ìœ¼ë¡œ ì¬ìƒì„±ë¨
        st.rerun()

with main_col:
    # ì±„íŒ… ê¸°ë¡ í‘œì‹œ
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])
    
    # ì‚¬ìš©ì ì…ë ¥
    user_input = st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”")
    
    if user_input:
        # ì‚¬ìš©ì ë©”ì‹œì§€ í‘œì‹œ
        with st.chat_message("user"):
            st.markdown(user_input)
        st.session_state.messages.append({"role": "user", "content": user_input})
        
        # AI ì‘ë‹µ ìƒì„±
        with st.chat_message("assistant"):
            with st.spinner("ë‹µë³€ ìƒì„± ì¤‘..."):
                try:
                    start_time = time.time()
                    
                    # ğŸš€ ì¼ë°˜ì ì¸ boto3.client í˜¸ì¶œ - ìë™ìœ¼ë¡œ ëª¨ë“  ëª¨ë‹ˆí„°ë§ ì²˜ë¦¬!
                    bedrock_client = get_bedrock_client()
                    
                    # ì²« ë²ˆì§¸ ë©”ì‹œì§€ì¸ ê²½ìš° ëª¨ë‹ˆí„°ë§ ìƒíƒœ í•œ ë²ˆ ë” í™•ì¸
                    if len(st.session_state.messages) <= 1:
                        try:
                            if hasattr(bedrock_client.invoke_model, '__wrapped__'):
                                st.info("ğŸ¯ ì²« ë²ˆì§¸ í˜¸ì¶œ - ëª¨ë‹ˆí„°ë§ í™œì„±í™” í™•ì¸ë¨!")
                            else:
                                st.warning("âš ï¸ ì²« ë²ˆì§¸ í˜¸ì¶œ - ëª¨ë‹ˆí„°ë§ ë¯¸í™•ì¸")
                        except Exception as check_error:
                            st.warning(f"ëª¨ë‹ˆí„°ë§ ì²´í¬ ì˜¤ë¥˜: {str(check_error)}")
                    
                    # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
                    combined_system_prompt = f"{st.session_state.user_role_prompt}\n\n{st.session_state.user_system_prompt}"
                    
                    response = bedrock_client.invoke_model(
                        modelId=MODEL_ID,
                        body=json.dumps({
                            "anthropic_version": "bedrock-2023-05-31",
                            "max_tokens": 1000,
                            "temperature": st.session_state.user_temperature,
                            "top_p": st.session_state.user_top_p,
                            "system": combined_system_prompt,
                            "messages": [
                                {
                                    "role": "user",
                                    "content": [{"type": "text", "text": user_input}]
                                }
                            ]
                        })
                    )
                    
                    # ì‘ë‹µ ì²˜ë¦¬ (ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ìë™ìœ¼ë¡œ í…ìŠ¤íŠ¸ ì¶”ì¶œ ë° New Relic ì „ì†¡)
                    response_body = json.loads(response['body'].read().decode('utf-8'))
                    
                    # ì‘ë‹µ í…ìŠ¤íŠ¸ ì¶”ì¶œ (fallback)
                    assistant_response = ""
                    if 'content' in response_body:
                        content = response_body['content']
                        if isinstance(content, list) and len(content) > 0:
                            if isinstance(content[0], dict) and 'text' in content[0]:
                                assistant_response = content[0]['text']
                    
                    if assistant_response:
                        st.markdown(assistant_response)
                        st.session_state.messages.append({"role": "assistant", "content": assistant_response})
                        
                        # ì‘ë‹µ ë°ì´í„° ì €ì¥ (í‰ê°€ UIìš©)
                        usage = response_body.get("usage", {})
                        total_duration = int((time.time() - start_time) * 1000)
                        
                        st.session_state.last_response_data = {
                            "response_time_ms": total_duration,
                            "total_tokens": usage.get("total_token_count", 0) or (usage.get("input_tokens", 0) + usage.get("output_tokens", 0)),
                            "prompt_tokens": usage.get("input_token_count", 0) or usage.get("input_tokens", 0),
                            "completion_tokens": usage.get("output_token_count", 0) or usage.get("output_tokens", 0),
                            "temperature": st.session_state.user_temperature,
                            "top_p": st.session_state.user_top_p
                        }
                    else:
                        st.error("ì‘ë‹µì„ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                        
                except Exception as e:
                    st.error(f"ì˜¤ë¥˜: {str(e)}")

# ğŸ“Š ëª¨ë‹ˆí„°ë§ ì •ë³´ ì„¹ì…˜
st.markdown("---")
col1, col2 = st.columns(2)

with col1:
    st.markdown("### ìë™ ìˆ˜ì§‘ë˜ëŠ” ë°ì´í„°")
    st.markdown("""
    **ìë™ìœ¼ë¡œ New Relicì— ì „ì†¡:**
    - âœ… LlmCompletion (ìš”ì²­/ì‘ë‹µ, í† í°, íŒŒë¼ë¯¸í„°)
    - âœ… LlmUserRole (ì‚¬ìš©ì ì…ë ¥ ì´ë²¤íŠ¸)  
    - âœ… LlmSystemRole (ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì´ë²¤íŠ¸)
    - âœ… LlmBedrockResponse (ì‘ë‹µ ìƒì„¸ ì •ë³´)
    - âœ… trace_id, completion_id (ìë™ ìƒì„±)
    - âœ… conversation_id (ì„¸ì…˜ ì—°ë™)
    """)

with col2:
    # New Relic ì¿¼ë¦¬ ì˜ˆì œ (ë¼ì´ë¸ŒëŸ¬ë¦¬ í•¨ìˆ˜ ì‚¬ìš©)
    create_streamlit_nrql_queries(
        application_name=APP_NAME,
        conversation_id=session_info.get('conversation_id')
    )

# ğŸ“ í‰ê°€ UI (ë§ˆì§€ë§‰ ì‘ë‹µì´ ìˆì„ ë•Œë§Œ í‘œì‹œ)
if (st.session_state.messages and 
    st.session_state.messages[-1]["role"] == "assistant" and
    st.session_state.last_response_data):
    
    st.markdown("---")
    
    # ë¼ì´ë¸ŒëŸ¬ë¦¬ì˜ ìë™ í‰ê°€ UI ì‚¬ìš© (New Relic ì „ì†¡ í¬í•¨)
    create_streamlit_evaluation_ui(
        # trace_idì™€ completion_idëŠ” ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ìë™ìœ¼ë¡œ ê´€ë¦¬
        model_id=MODEL_ID,
        response_time_ms=st.session_state.last_response_data.get("response_time_ms"),
        total_tokens=st.session_state.last_response_data.get("total_tokens"),
        prompt_tokens=st.session_state.last_response_data.get("prompt_tokens"),
        completion_tokens=st.session_state.last_response_data.get("completion_tokens"),
        temperature=st.session_state.last_response_data.get("temperature"),
        top_p=st.session_state.last_response_data.get("top_p"),
        application_name=APP_NAME
    )

# í‘¸í„°
st.markdown("---")
st.markdown(
    "nr-bedrock-observability-python v2.4.1 - ìë™ íŒ¨ì¹˜ ëª¨ë“œ"
) 