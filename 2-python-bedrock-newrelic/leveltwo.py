"""
AWS Bedrock ëª¨ë‹ˆí„°ë§ ì• í”Œë¦¬ì¼€ì´ì…˜ (Streamlit) - Knowledge Base ì—†ì´ ì§ì ‘ Bedrock í˜¸ì¶œ

ì´ ì•±ì€ AWS Bedrock API í˜¸ì¶œì„ ëª¨ë‹ˆí„°ë§í•˜ê³  NewRelicì— ë°ì´í„°ë¥¼ ì „ì†¡í•©ë‹ˆë‹¤.
ì§€ì‹ ê¸°ë°˜ ì—†ì´ Claude 3.5 Sonnet ëª¨ë¸ì„ ì§ì ‘ ì‚¬ìš©í•˜ì—¬ ì§ˆë¬¸ì— ë‹µë³€í•˜ê³  ì‚¬ìš©ì í”¼ë“œë°±ì„ ìˆ˜ì§‘í•©ë‹ˆë‹¤.
"""

import streamlit as st
import boto3
import json
import uuid
import time
import os
import newrelic.agent
from nr_bedrock_observability import (
    monitor_bedrock, 
    # í‰ê°€ ìˆ˜ì§‘ ë„êµ¬
    init_response_evaluation_collector,
    ensure_evaluation_state,
    update_evaluation_state,
    create_update_callback,
    create_evaluation_ui,
    create_evaluation_debug_ui,
    send_evaluation_with_newrelic_agent,
    get_evaluation_collector,
    reset_evaluation_collector,
    # ìƒˆë¡œ ì¶”ê°€ëœ ëŒ€ì‹œë³´ë“œ í—¬í¼ í•¨ìˆ˜
    record_role_based_events,
    # record_search_results,  # Knowledge Base ì—†ì´ëŠ” ì‚¬ìš©í•˜ì§€ ì•ŠìŒ
    record_bedrock_response,
    extract_claude_response_text,
    get_sample_nrql_queries,
    # search_knowledge_base  # Knowledge Base ì—†ì´ëŠ” ì‚¬ìš©í•˜ì§€ ì•ŠìŒ
)

# NewRelic ë¼ì´ì„¼ìŠ¤ í‚¤ ì„¤ì • - ì‹¤ì œ í™˜ê²½ì—ì„œëŠ” í™˜ê²½ ë³€ìˆ˜ë‚˜ ë³´ì•ˆ ë°©ì‹ìœ¼ë¡œ ê´€ë¦¬í•´ì•¼ í•©ë‹ˆë‹¤
os.environ["NEW_RELIC_LICENSE_KEY"] = "XXXXXXXXXXXX"  # ì‹¤ì œ ë¼ì´ì„¼ìŠ¤ í‚¤ë¡œ ë³€ê²½ í•„ìš”

# ìƒìˆ˜ ì •ì˜
REGION = "ap-northeast-2"
MODEL_ID = "anthropic.claude-3-5-sonnet-20240620-v1:0"
# KNOWLEDGE_BASE_ID = "VNJYWIISJU"  # Knowledge Base ì—†ì´ëŠ” ì‚¬ìš©í•˜ì§€ ì•ŠìŒ
# KNOWLEDGE_BASE_NAME = "knowledge-base-quick-start-ycffx"  # Knowledge Base ì—†ì´ëŠ” ì‚¬ìš©í•˜ì§€ ì•ŠìŒ
APP_NAME = "gen-ai-bedrock-app"

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="Bedrock ëª¨ë‹ˆí„°ë§ ì•± (ì§ì ‘ í˜¸ì¶œ)",
    page_icon="ğŸ¤–",
    layout="wide"
)

# ë‰´ë ë¦­ ì„¤ì • í™•ì¸
try:
    nr_app = newrelic.agent.application()
    if nr_app:
        st.success(f"ë‰´ë ë¦­ ì• í”Œë¦¬ì¼€ì´ì…˜ì´ ì„±ê³µì ìœ¼ë¡œ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤: {nr_app.name}")
    else:
        st.warning(f"ë‰´ë ë¦­ ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë¼ì´ì„¼ìŠ¤ í‚¤ë¥¼ í™•ì¸í•˜ì„¸ìš”: {os.environ.get('NEW_RELIC_LICENSE_KEY', '').replace('FFFFNRAL', '****')}")
except Exception as e:
    st.error(f"ë‰´ë ë¦­ ì´ˆê¸°í™” ì˜¤ë¥˜: {str(e)}")

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "trace_id" not in st.session_state:
    st.session_state.trace_id = str(uuid.uuid4())
if "conversation_id" not in st.session_state:
    st.session_state.conversation_id = str(uuid.uuid4())
if "messages" not in st.session_state:
    st.session_state.messages = []
if "current_completion_id" not in st.session_state:
    st.session_state.current_completion_id = None
if "raw_result" not in st.session_state:
    st.session_state.raw_result = {}
# Knowledge Base ê´€ë ¨ ì„¸ì…˜ ìƒíƒœëŠ” ì‚¬ìš©í•˜ì§€ ì•ŠìŒ
# if "current_search_results" not in st.session_state:
#     st.session_state.current_search_results = []
if "current_system_prompt" not in st.session_state:
    st.session_state.current_system_prompt = ""
if "message_count" not in st.session_state:
    st.session_state.message_count = 0
# ì‚¬ìš©ì ì„¤ì • ê°€ëŠ¥í•œ íŒŒë¼ë¯¸í„°ë“¤ ì´ˆê¸°í™”
if "user_role_prompt" not in st.session_state:
    st.session_state.user_role_prompt = "ë‹¹ì‹ ì€ ë„ì›€ì´ ë˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤."
if "user_system_prompt" not in st.session_state:
    st.session_state.user_system_prompt = "ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëª…í™•í•˜ê³  ì •í™•í•˜ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”. í•œêµ­ì–´ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”."
if "user_temperature" not in st.session_state:
    st.session_state.user_temperature = 0.3
if "user_top_p" not in st.session_state:
    st.session_state.user_top_p = 0.9

# í‰ê°€ ìˆ˜ì§‘ê¸° ì´ˆê¸°í™”
if "response_evaluation_collector" not in st.session_state:
    try:
        # ìƒˆë¡œìš´ í‰ê°€ ìˆ˜ì§‘ê¸° ì´ˆê¸°í™”
        init_response_evaluation_collector(
            application_name=APP_NAME,
            trace_id=st.session_state.trace_id,
            completion_id=None,
            session_id=st.session_state.conversation_id,
            collector_session_key="response_evaluation_collector"
        )
    except Exception as e:
        st.warning(f"í‰ê°€ ìˆ˜ì§‘ê¸° ì´ˆê¸°í™” ì¤‘ ì˜¤ë¥˜: {str(e)}")

# Bedrock í´ë¼ì´ì–¸íŠ¸ ì„¤ì •
@st.cache_resource
def get_bedrock_client():
    """Bedrock ëŸ°íƒ€ì„ í´ë¼ì´ì–¸íŠ¸ë¥¼ ìƒì„±í•˜ê³  ëª¨ë‹ˆí„°ë§ ì„¤ì •"""
    bedrock_client = boto3.client('bedrock-runtime', region_name=REGION)
    monitored_client = monitor_bedrock(bedrock_client, {
        'application_name': APP_NAME,
        'new_relic_api_key': os.environ.get("NEW_RELIC_LICENSE_KEY")
    })
    return monitored_client

# Knowledge Base ì—†ì´ ì§ì ‘ Bedrock í˜¸ì¶œí•˜ëŠ” ì›Œí¬í”Œë¡œìš°
def run_direct_bedrock_workflow(user_query):
    """ì§ì ‘ Bedrock ì›Œí¬í”Œë¡œìš° ì‹¤í–‰: Knowledge Base ì—†ì´ Claude 3.5 Sonnetì— ì§ì ‘ ì§ˆë¬¸"""
    start_time = time.time()
    
    # ìƒˆ ì™„ì„± ID ìƒì„±í•˜ê³  ê¸°ì¡´ ëŒ€í™” ID ìœ ì§€
    trace_id = str(uuid.uuid4())
    completion_id = str(uuid.uuid4())
    conversation_id = st.session_state.conversation_id
    st.session_state.current_completion_id = completion_id
    st.session_state.message_count += 1
    message_index = st.session_state.message_count
    
    # íŠ¸ë ˆì´ìŠ¤ ID ë””ë²„ê¹… ì¶œë ¥
    st.info(f"ì§ì ‘ í˜¸ì¶œ - ëŒ€í™” ID: {conversation_id}, íŠ¸ë ˆì´ìŠ¤ ID: {trace_id}, ì™„ì„± ID: {completion_id}, ë©”ì‹œì§€ ìˆœì„œ: {message_index}")
    
    # ì‘ë‹µ í‰ê°€ ìˆ˜ì§‘ê¸° ì´ˆê¸°í™” ë˜ëŠ” ì—…ë°ì´íŠ¸
    try:
        init_response_evaluation_collector(
            application_name=APP_NAME,
            trace_id=trace_id,
            completion_id=completion_id,
            user_id=None,
            session_id=conversation_id
        )
    except Exception as e:
        st.warning(f"ì‘ë‹µ í‰ê°€ ìˆ˜ì§‘ê¸° ì´ˆê¸°í™” ì¤‘ ì˜¤ë¥˜: {str(e)}")
    
    # Knowledge Base ê²€ìƒ‰ ë‹¨ê³„ëŠ” ìƒëµ
    # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ì™€ ì‚¬ìš©ì ì¿¼ë¦¬ êµ¬ì„±
    # role promptì™€ system promptë¥¼ í•©ì³ì„œ ì „ì²´ system prompt ìƒì„±
    combined_system_prompt = f"{st.session_state.user_role_prompt}\n\n{st.session_state.user_system_prompt}"
    system_prompt = combined_system_prompt
    
    # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì €ì¥
    st.session_state.current_system_prompt = system_prompt
    
    # ì‚¬ìš©ì ì¿¼ë¦¬ë¥¼ ì§ì ‘ ì‚¬ìš© (Knowledge Base ì»¨í…ìŠ¤íŠ¸ ì—†ì´)
    user_content = user_query
    
    # ì—­í• ë³„ ì´ë²¤íŠ¸ ê¸°ë¡ - Knowledge Base ê²€ìƒ‰ ê²°ê³¼ ì—†ì´
    record_role_based_events(
        user_query=user_query,
        system_prompt=system_prompt,
        search_results=[],  # ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ
        context_text="",    # ì»¨í…ìŠ¤íŠ¸ ì—†ìŒ
        trace_id=trace_id,
        completion_id=completion_id,
        application_name=APP_NAME,
        conversation_id=conversation_id,
        message_index=message_index
    )
    
    # Knowledge Base ê²€ìƒ‰ ê²°ê³¼ ê¸°ë¡ì€ ìƒëµ
    # record_search_results(...) í˜¸ì¶œ ì—†ìŒ
    
    # Bedrock ìš”ì²­ êµ¬ì„± - Claude 3.5 Sonnet í˜•ì‹ì— ë§ì¶¤
    request = {
        'modelId': MODEL_ID,
        'body': json.dumps({
            "anthropic_version": "bedrock-2023-05-31",
            'max_tokens': 1000,
            'temperature': st.session_state.user_temperature,
            'top_p': st.session_state.user_top_p,
            'system': system_prompt,
            'messages': [
                {
                    'role': 'user',
                    'content': [
                        {
                            'type': 'text',
                            'text': user_content
                        }
                    ]
                }
            ]
        })
    }
    
    # ëª¨ë¸ íŒŒë¼ë¯¸í„° ì¶”ì¶œ (temperatureì™€ top_p)
    request_body = json.loads(request['body'])
    temperature = request_body.get('temperature', 0.3)
    top_p = request_body.get('top_p', 0.9)
    
    # Bedrock ìš”ì²­ ì‹¤í–‰
    try:
        # Bedrock í˜¸ì¶œ
        bedrock_client = get_bedrock_client()
        response = bedrock_client.invoke_model(**request)
        response_body = json.loads(response['body'].read().decode('utf-8'))
        
        # ì‘ë‹µ í…ìŠ¤íŠ¸ ì¶”ì¶œ - ë¼ì´ë¸ŒëŸ¬ë¦¬ í•¨ìˆ˜ ì‚¬ìš©
        assistant_response = extract_claude_response_text(response_body)
        
        # Bedrock ì‘ë‹µì„ New Relicì— ê¸°ë¡ - Knowledge Base ì •ë³´ ì—†ì´
        record_bedrock_response(
            assistant_response=assistant_response,
            response_body=response_body,
            trace_id=trace_id,
            completion_id=completion_id,
            application_name=APP_NAME,
            model_id=MODEL_ID,
            kb_id=None,  # Knowledge Base ì—†ìŒ
            kb_name=None,  # Knowledge Base ì—†ìŒ
            conversation_id=conversation_id,
            message_index=message_index,
            response_time_ms=int((time.time() - start_time) * 1000),
            temperature=temperature,
            top_p=top_p
        )
        
        # í† í° ì‚¬ìš©ëŸ‰ ì¶”ì¶œ - Claude 3.5 í˜¸í™˜
        usage = response_body.get("usage", {})
        # ì¼ë°˜ Bedrock í† í° í•„ë“œ í™•ì¸
        total_tokens = usage.get("total_token_count", 0)
        input_tokens = usage.get("input_token_count", 0)
        output_tokens = usage.get("output_token_count", 0)
        
        # Claude 3.5 í† í° í•„ë“œ í™•ì¸
        if total_tokens == 0:
            input_tokens = usage.get("input_tokens", 0)
            output_tokens = usage.get("output_tokens", 0)
            total_tokens = input_tokens + output_tokens
        
        # ì „ì²´ ì²˜ë¦¬ ì™„ë£Œ ì‹œê°„ ì¸¡ì •
        total_duration = int((time.time() - start_time) * 1000)  # ë°€ë¦¬ì´ˆë¡œ ë³€í™˜
        
        return assistant_response, {
            # "search_results": [],  # ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ
            # "search_time_ms": 0,   # ê²€ìƒ‰ ì‹œê°„ ì—†ìŒ
            "llm_time_ms": total_duration,
            "total_time_ms": total_duration,
            "trace_id": trace_id,
            "completion_id": completion_id,
            "token_count": output_tokens,
            "total_tokens": total_tokens,
            "prompt_tokens": input_tokens,
            "model_id": MODEL_ID,
            "kb_id": None,  # Knowledge Base ì—†ìŒ
            "kb_name": None,  # Knowledge Base ì—†ìŒ
            "kb_used_in_query": False,  # Knowledge Base ì‚¬ìš© ì•ˆí•¨
            "response_time_ms": total_duration,
            "temperature": temperature,
            "top_p": top_p
        }
        
    except Exception as e:
        st.error(f"Bedrock í˜¸ì¶œ ì˜¤ë¥˜: {str(e)}")
        return None, None

# UI êµ¬ì„± í•¨ìˆ˜
def build_ui():
    """Streamlit UI êµ¬ì„±"""
    st.title("ğŸ¤– AWS Bedrock ì§ì ‘ í˜¸ì¶œ Q&A + ëª¨ë‹ˆí„°ë§")
    
    # ë ˆì´ì•„ì›ƒ: ë©”ì¸ ì»¬ëŸ¼ê³¼ ì‚¬ì´ë“œë°”
    main_col, info_col = st.columns([2, 1])
    
    with info_col:
        st.header("ì•± ì •ë³´")
        st.markdown(f"""
        **ëª¨ë¸**: {MODEL_ID}
        
        **Knowledge Base**: ì‚¬ìš© ì•ˆí•¨ (ì§ì ‘ í˜¸ì¶œ)
        
        **ë¦¬ì „**: {REGION}
        
        **NewRelic ì•± ì´ë¦„**: {APP_NAME}
        """)
        
        # ëª¨ë¸ íŒŒë¼ë¯¸í„° ì„¤ì • ì„¹ì…˜ ì¶”ê°€
        st.header("ëª¨ë¸ íŒŒë¼ë¯¸í„° ì„¤ì •")
        
        # í”„ë¦¬ì…‹ ë²„íŠ¼ë“¤
        st.subheader("ë¹ ë¥¸ ì„¤ì • í”„ë¦¬ì…‹")
        col1, col2, col3 = st.columns(3)
        
        with col1:
            if st.button("ğŸ¥ ì˜ë£Œ ì „ë¬¸ê°€", help="ì˜ë£Œ ê´€ë ¨ ì§ˆë¬¸ì— íŠ¹í™”ëœ ì„¤ì •"):
                st.session_state.user_role_prompt = "ë‹¹ì‹ ì€ 15ë…„ ê²½ë ¥ì˜ ì„ìƒ ì˜ì‚¬ì´ì ë‚´ê³¼ ì „ë¬¸ì˜ì…ë‹ˆë‹¤. í™˜ìë“¤ì—ê²Œ ì‹¤ìš©ì ì´ê³  êµ¬ì²´ì ì¸ ì˜í•™ì  ì¡°ì–¸ì„ ì œê³µí•˜ëŠ” ê²ƒì´ ë‹¹ì‹ ì˜ ì „ë¬¸ ë¶„ì•¼ì…ë‹ˆë‹¤."
                st.session_state.user_system_prompt = """ë‹¤ìŒ ì›ì¹™ì— ë”°ë¼ ì˜í•™ì  ì¡°ì–¸ì„ ì œê³µí•˜ì„¸ìš”:

1. **ì „ë¬¸ì  ì§„ë‹¨ê³¼ ì¹˜ë£Œ ê¶Œê³ **: ì¦ìƒì„ ë¶„ì„í•˜ê³  ê°€ëŠ¥í•œ ì›ì¸ì„ ì œì‹œí•˜ë©°, ì¼ë°˜ì˜ì•½í’ˆì´ë‚˜ ìƒí™œìŠµê´€ ê°œì„  ë“± êµ¬ì²´ì ì¸ í•´ê²°ì±…ì„ ì œì•ˆí•˜ì„¸ìš”.

2. **ë‹¨ê³„ë³„ ì¹˜ë£Œ ì ‘ê·¼**: ê²½ì¦ì˜ ê²½ìš° ìê°€ ê´€ë¦¬ ë°©ë²•ë¶€í„° ì‹œì‘í•˜ì—¬, í•„ìš”ì‹œ ì „ë¬¸ì˜ ì§„ë£Œë¥¼ ê¶Œí•˜ëŠ” ë‹¨ê³„ì  ì ‘ê·¼ë²•ì„ ì‚¬ìš©í•˜ì„¸ìš”.

3. **ì‹¤ìš©ì  ì•½ë¬¼ ì •ë³´**: ì¼ë°˜ì˜ì•½í’ˆì˜ ê²½ìš° êµ¬ì²´ì ì¸ ì„±ë¶„ëª…, ìš©ë²•Â·ìš©ëŸ‰, ì£¼ì˜ì‚¬í•­ì„ ëª…í™•íˆ ì œì‹œí•˜ì„¸ìš”.

4. **ìœ„í—˜ ì‹ í˜¸ ì¸ì‹**: ì‘ê¸‰ ìƒí™©ì´ë‚˜ ì „ë¬¸ì˜ ì§„ë£Œê°€ ë°˜ë“œì‹œ í•„ìš”í•œ ê²½ìš°ë¥¼ ëª…í™•íˆ êµ¬ë¶„í•˜ì—¬ ì•ˆë‚´í•˜ì„¸ìš”.

5. **ê°œì¸í™”ëœ ì¡°ì–¸**: ì—°ë ¹, ê¸°ì¡´ ì§ˆí™˜, ë³µìš© ì¤‘ì¸ ì•½ë¬¼ ë“±ì„ ê³ ë ¤í•œ ë§ì¶¤í˜• ì¡°ì–¸ì„ ì œê³µí•˜ì„¸ìš”.

í•­ìƒ ì˜í•™ì  ê·¼ê±°ë¥¼ ë°”íƒ•ìœ¼ë¡œ í•˜ë˜, í™˜ìê°€ ì‹¤ì œë¡œ í™œìš©í•  ìˆ˜ ìˆëŠ” êµ¬ì²´ì ì´ê³  ì‹¤ìš©ì ì¸ ì •ë³´ë¥¼ ìš°ì„  ì œê³µí•˜ì„¸ìš”. í•œêµ­ì–´ë¡œ ëª…í™•í•˜ê³  ì´í•´í•˜ê¸° ì‰½ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”."""
                st.session_state.user_temperature = 0.2
                st.session_state.user_top_p = 0.8
                st.rerun()
        
        with col2:
            if st.button("ğŸ’» ì½”ë”© íŠœí„°", help="í”„ë¡œê·¸ë˜ë° í•™ìŠµì— íŠ¹í™”ëœ ì„¤ì •"):
                st.session_state.user_role_prompt = "ë‹¹ì‹ ì€ 10ë…„ ì´ìƒì˜ ì‹¤ë¬´ ê²½í—˜ì„ ê°€ì§„ ì‹œë‹ˆì–´ ê°œë°œìì´ì í”„ë¡œê·¸ë˜ë° êµìœ¡ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹¤ì–‘í•œ í”„ë¡œê·¸ë˜ë° ì–¸ì–´ì™€ í”„ë ˆì„ì›Œí¬ì— ëŠ¥í†µí•˜ë©°, ë³µì¡í•œ ê°œë…ì„ ì‰½ê²Œ ì„¤ëª…í•˜ëŠ” ê²ƒì´ íŠ¹ê¸°ì…ë‹ˆë‹¤."
                st.session_state.user_system_prompt = """ë‹¤ìŒ êµìœ¡ ë°©ë²•ë¡ ì— ë”°ë¼ í”„ë¡œê·¸ë˜ë° ì§€ë„ë¥¼ í•´ì£¼ì„¸ìš”:

1. **ë‹¨ê³„ë³„ í•™ìŠµ ì ‘ê·¼**:
   - ê°œë… ì„¤ëª… â†’ ê°„ë‹¨í•œ ì˜ˆì œ â†’ ì‹¤ìŠµ ë¬¸ì œ â†’ ì‹¬í™” ì‘ìš© ìˆœì„œë¡œ ì§„í–‰
   - í•™ìŠµìì˜ ìˆ˜ì¤€ì— ë§ëŠ” ì ì ˆí•œ ë‚œì´ë„ ì¡°ì ˆ

2. **ì‹¤ìŠµ ì¤‘ì‹¬ êµìœ¡**:
   - ëª¨ë“  ê°œë…ì— ëŒ€í•´ ì‹¤í–‰ ê°€ëŠ¥í•œ ì½”ë“œ ì˜ˆì œ ì œê³µ
   - ì£¼ì„ì„ ìƒì„¸íˆ ë‹¬ì•„ ì½”ë“œì˜ ê° ë¶€ë¶„ ì„¤ëª…
   - ì‹¤ì œ í”„ë¡œì íŠ¸ì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ì‹¤ìš©ì ì¸ ì˜ˆì œ ìš°ì„ 

3. **ë””ë²„ê¹…ê³¼ ë¬¸ì œ í•´ê²°**:
   - ìì£¼ ë°œìƒí•˜ëŠ” ì˜¤ë¥˜ì™€ í•´ê²° ë°©ë²• ì„¤ëª…
   - ì½”ë“œ ë¦¬ë·° ê´€ì ì—ì„œ ê°œì„ ì  ì œì‹œ
   - íš¨ìœ¨ì ì¸ ë””ë²„ê¹… ë°©ë²• ì•ˆë‚´

4. **ëª¨ë²” ì‚¬ë¡€ì™€ ì½”ë”© í‘œì¤€**:
   - í´ë¦° ì½”ë“œ ì‘ì„± ì›ì¹™ ì ìš©
   - ì—…ê³„ í‘œì¤€ê³¼ ëª¨ë²” ì‚¬ë¡€ ì†Œê°œ
   - ì„±ëŠ¥ ìµœì í™”ì™€ ìœ ì§€ë³´ìˆ˜ì„± ê³ ë ¤

5. **í•™ìŠµ ë™ê¸° ë¶€ì—¬**:
   - ì‹¤ë¬´ì—ì„œì˜ í™œìš© ì‚¬ë¡€ ì œì‹œ
   - ë‹¨ê³„ë³„ ì„±ì·¨ê° ì œê³µ
   - ì¶”ê°€ í•™ìŠµ ìë£Œì™€ ë°œì „ ë°©í–¥ ì œì•ˆ

í•­ìƒ 'ì™œ ì´ë ‡ê²Œ ì‘ì„±í•˜ëŠ”ê°€?'ì— ëŒ€í•œ ì´ìœ ë¥¼ ì„¤ëª…í•˜ê³ , ëŒ€ì•ˆì  ì ‘ê·¼ë²•ë„ í•¨ê»˜ ì œì‹œí•˜ì„¸ìš”. í•œêµ­ì–´ë¡œ ì¹œê·¼í•˜ê³  ì´í•´í•˜ê¸° ì‰½ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”."""
                st.session_state.user_temperature = 0.4
                st.session_state.user_top_p = 0.9
                st.rerun()
        
        with col3:
            if st.button("ğŸ¨ ì°½ì˜ì  ì‘ê°€", help="ì°½ì‘ í™œë™ì— íŠ¹í™”ëœ ì„¤ì •"):
                st.session_state.user_role_prompt = "ë‹¹ì‹ ì€ ë² ìŠ¤íŠ¸ì…€ëŸ¬ ì‘í’ˆì„ ì—¬ëŸ¬ í¸ ì¶œê°„í•œ ì „ë¬¸ ì‘ê°€ì´ì ì°½ì‘ ì§€ë„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì†Œì„¤, ì—ì„¸ì´, ì‹œë‚˜ë¦¬ì˜¤ ë“± ë‹¤ì–‘í•œ ì¥ë¥´ì— ëŠ¥í†µí•˜ë©°, ë…ìì˜ ë§ˆìŒì„ ì‚¬ë¡œì¡ëŠ” ìŠ¤í† ë¦¬í…”ë§ì´ íŠ¹ê¸°ì…ë‹ˆë‹¤."
                st.session_state.user_system_prompt = """ë‹¤ìŒ ì°½ì‘ ì›ì¹™ì— ë”°ë¼ ê¸€ì“°ê¸° ì§€ë„ë¥¼ í•´ì£¼ì„¸ìš”:

1. **ì°½ì‘ í”„ë¡œì„¸ìŠ¤ ì•ˆë‚´**:
   - ì•„ì´ë””ì–´ ë°œêµ´ â†’ êµ¬ì„± ê³„íš â†’ ì´ˆê³  ì‘ì„± â†’ ìˆ˜ì •/í¸ì§‘ ë‹¨ê³„ë³„ ê°€ì´ë“œ
   - ê° ë‹¨ê³„ì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” êµ¬ì²´ì ì¸ ê¸°ë²•ê³¼ ë„êµ¬ ì œì‹œ

2. **ìŠ¤í† ë¦¬í…”ë§ êµ¬ì¡°**:
   - ë§¤ë ¥ì ì¸ ë„ì…ë¶€, ê¸´ì¥ê° ìˆëŠ” ì „ê°œ, ë§Œì¡±ìŠ¤ëŸ¬ìš´ ê²°ë§ êµ¬ì„±ë²•
   - ìºë¦­í„° ê°œë°œê³¼ ê°ˆë“± êµ¬ì¡° ì„¤ê³„
   - ì¥ë¥´ë³„ íŠ¹ì„±ì„ ê³ ë ¤í•œ ë§ì¶¤í˜• ì¡°ì–¸

3. **ë¬¸ì²´ì™€ í‘œí˜„ë ¥**:
   - ìƒí™©ê³¼ ê°ì •ì— ë§ëŠ” ìƒìƒí•œ ë¬˜ì‚¬ ê¸°ë²•
   - ë…ìì˜ ê³µê°ì„ ì´ëŒì–´ë‚´ëŠ” í‘œí˜„ ë°©ë²•
   - ë¬¸ì¥ ë¦¬ë“¬ê³¼ í˜¸í¡ì„ ê³ ë ¤í•œ ê¸€ì“°ê¸°

4. **ë…ì°½ì„±ê³¼ ì°¨ë³„í™”**:
   - ê¸°ì¡´ ì‘í’ˆê³¼ ì°¨ë³„í™”ë˜ëŠ” ë…íŠ¹í•œ ê´€ì  ì œì‹œ
   - ê°œì¸ì  ê²½í—˜ê³¼ ìƒìƒë ¥ì„ ê²°í•©í•œ ì˜¤ë¦¬ì§€ë„ ì•„ì´ë””ì–´ ê°œë°œ
   - íŠ¸ë Œë“œë¥¼ ë°˜ì˜í•˜ë©´ì„œë„ ì‹œëŒ€ë¥¼ ì´ˆì›”í•˜ëŠ” ë³´í¸ì„± ì¶”êµ¬

5. **ì‹¤ìš©ì  ê¸€ì“°ê¸° ì¡°ì–¸**:
   - ì‘ê°€ì˜ ë¸”ë¡ ê·¹ë³µ ë°©ë²•
   - íš¨ê³¼ì ì¸ ìë£Œ ì¡°ì‚¬ì™€ ì·¨ì¬ ë°©ë²•
   - ì¶œê°„ê³¼ ë…ì ì†Œí†µì„ ìœ„í•œ ì‹¤ë¬´ì  ì¡°ì–¸

í•­ìƒ êµ¬ì²´ì ì¸ ì˜ˆì‹œì™€ í•¨ê»˜ ì„¤ëª…í•˜ê³ , ì°½ì‘ìì˜ ê°œì„±ì„ ì‚´ë¦´ ìˆ˜ ìˆëŠ” ë‹¤ì–‘í•œ ì ‘ê·¼ë²•ì„ ì œì•ˆí•˜ì„¸ìš”. í•œêµ­ì–´ì˜ ì•„ë¦„ë‹¤ì›€ì„ ì‚´ë¦° í’ë¶€í•œ í‘œí˜„ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”."""
                st.session_state.user_temperature = 0.8
                st.session_state.user_top_p = 0.95
                st.rerun()
        
        # ê¸°ë³¸ ì„¤ì • ë³µì› ë²„íŠ¼
        if st.button("ğŸ”„ ê¸°ë³¸ ì„¤ì • ë³µì›", help="ëª¨ë“  ì„¤ì •ì„ ê¸°ë³¸ê°’ìœ¼ë¡œ ë˜ëŒë¦½ë‹ˆë‹¤"):
            st.session_state.user_role_prompt = "ë‹¹ì‹ ì€ ë„ì›€ì´ ë˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤."
            st.session_state.user_system_prompt = "ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëª…í™•í•˜ê³  ì •í™•í•˜ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”. í•œêµ­ì–´ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”."
            st.session_state.user_temperature = 0.3
            st.session_state.user_top_p = 0.9
            st.rerun()
        
        st.markdown("---")  # êµ¬ë¶„ì„  ì¶”ê°€
        
        # Role Prompt ì…ë ¥
        st.subheader("Role Prompt")
        new_role_prompt = st.text_area(
            "ëª¨ë¸ì˜ ì—­í• ì„ ì •ì˜í•˜ì„¸ìš”:",
            value=st.session_state.user_role_prompt,
            height=80,
            key="role_prompt_input",
            help="ì˜ˆ: 'ë‹¹ì‹ ì€ ì˜ë£Œ ì „ë¬¸ê°€ì…ë‹ˆë‹¤', 'ë‹¹ì‹ ì€ ì½”ë”© íŠœí„°ì…ë‹ˆë‹¤' ë“±"
        )
        if new_role_prompt != st.session_state.user_role_prompt:
            st.session_state.user_role_prompt = new_role_prompt
        
        # System Prompt ì…ë ¥
        st.subheader("System Prompt")
        new_system_prompt = st.text_area(
            "êµ¬ì²´ì ì¸ í–‰ë™ ì§€ì¹¨ì„ ì…ë ¥í•˜ì„¸ìš”:",
            value=st.session_state.user_system_prompt,
            height=100,
            key="system_prompt_input",
            help="ëª¨ë¸ì´ ì–´ë–»ê²Œ í–‰ë™í•´ì•¼ í•˜ëŠ”ì§€ êµ¬ì²´ì ìœ¼ë¡œ ëª…ì‹œí•˜ì„¸ìš”"
        )
        if new_system_prompt != st.session_state.user_system_prompt:
            st.session_state.user_system_prompt = new_system_prompt
        
        # Temperature ìŠ¬ë¼ì´ë”
        st.subheader("Temperature")
        new_temperature = st.slider(
            "ì°½ì˜ì„± ìˆ˜ì¤€ (ë‚®ì„ìˆ˜ë¡ ì¼ê´€ì„± ë†’ìŒ)",
            min_value=0.0,
            max_value=1.0,
            value=st.session_state.user_temperature,
            step=0.1,
            key="temperature_slider",
            help="0.0: ë§¤ìš° ì¼ê´€ì , 1.0: ë§¤ìš° ì°½ì˜ì "
        )
        if new_temperature != st.session_state.user_temperature:
            st.session_state.user_temperature = new_temperature
        
        # Top-p ìŠ¬ë¼ì´ë”
        st.subheader("Top-p (Nucleus Sampling)")
        new_top_p = st.slider(
            "ì‘ë‹µ ë‹¤ì–‘ì„± ì œì–´",
            min_value=0.0,
            max_value=1.0,
            value=st.session_state.user_top_p,
            step=0.1,
            key="top_p_slider",
            help="0.0: ê°€ì¥ í™•ë¥  ë†’ì€ ë‹¨ì–´ë§Œ, 1.0: ëª¨ë“  ë‹¨ì–´ ê³ ë ¤"
        )
        if new_top_p != st.session_state.user_top_p:
            st.session_state.user_top_p = new_top_p
            
        # í˜„ì¬ ì„¤ì • ë¯¸ë¦¬ë³´ê¸°
        with st.expander("í˜„ì¬ íŒŒë¼ë¯¸í„° ì„¤ì •", expanded=False):
            st.markdown("**ìµœì¢… System Prompt:**")
            combined_preview = f"{st.session_state.user_role_prompt}\n\n{st.session_state.user_system_prompt}"
            st.code(combined_preview)
            st.markdown(f"**Temperature:** {st.session_state.user_temperature}")
            st.markdown(f"**Top-p:** {st.session_state.user_top_p}")
        
        # íŠ¸ë ˆì´ìŠ¤ ì •ë³´
        st.subheader("íŠ¸ë ˆì´ìŠ¤ ì •ë³´")
        
        # ID ì„¤ëª… ì¶”ê°€
        with st.expander("ID ì„¤ëª…", expanded=True):
            st.markdown("""
            **ëŒ€í™” ID (Conversation ID)**: ì‚¬ìš©ìì˜ ì „ì²´ ëŒ€í™” ì„¸ì…˜ì„ ì‹ë³„í•˜ëŠ” ê³ ìœ  IDì…ë‹ˆë‹¤. ìƒˆë¡œìš´ ëŒ€í™” ì„¸ì…˜ì´ ì‹œì‘ë  ë•Œ ìƒì„±ë˜ë©°, ì‚¬ìš©ìê°€ ì—¬ëŸ¬ ë©”ì‹œì§€ë¥¼ ì£¼ê³ ë°›ëŠ” ë™ì•ˆ ë™ì¼í•˜ê²Œ ìœ ì§€ë©ë‹ˆë‹¤. ì „ì²´ ëŒ€í™” íë¦„ì„ ì¶”ì í•  ë•Œ ì‚¬ìš©ë©ë‹ˆë‹¤.
            
            **íŠ¸ë ˆì´ìŠ¤ ID (Trace ID)**: ê° ë©”ì‹œì§€ êµí™˜ì„ ì¶”ì í•˜ê¸° ìœ„í•œ IDì…ë‹ˆë‹¤. ìƒˆë¡œìš´ ì‚¬ìš©ì ì…ë ¥ì´ ìˆì„ ë•Œë§ˆë‹¤ ìƒˆë¡œìš´ íŠ¸ë ˆì´ìŠ¤ IDê°€ ìƒì„±ë©ë‹ˆë‹¤. ë‹¨ì¼ ìš”ì²­ì˜ ì „ì²´ ì²˜ë¦¬ ê³¼ì •(Bedrock ì§ì ‘ í˜¸ì¶œ)ì„ ì¶”ì í•˜ëŠ” ë° ì‚¬ìš©ë©ë‹ˆë‹¤.
            
            **ì™„ì„± ID (Completion ID)**: LLM ì‘ë‹µ ì™„ì„±ì— ëŒ€í•œ ê³ ìœ  IDì…ë‹ˆë‹¤. Bedrock API í˜¸ì¶œì˜ ê²°ê³¼ë¥¼ ì‹ë³„í•˜ê³  ì¶”ì í•˜ëŠ” ë° ì‚¬ìš©ë©ë‹ˆë‹¤. ê° ì™„ì„±ì€ íŠ¹ì • ì‚¬ìš©ì ì§ˆë¬¸ì— ëŒ€í•œ ëª¨ë¸ì˜ ì‘ë‹µì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.
            """)
        
        st.code(f"ëŒ€í™” ID: {st.session_state.conversation_id}")
        st.code(f"íŠ¸ë ˆì´ìŠ¤ ID: {st.session_state.trace_id}")
        if st.session_state.current_completion_id:
            st.code(f"ì™„ì„± ID: {st.session_state.current_completion_id}")
            
            # ëª¨ë¸ í‰ê°€ ë¶„ì„ NRQL ì˜ˆì‹œ ì¶”ê°€
            with st.expander("ëª¨ë¸ í‰ê°€ ë¶„ì„ ì¿¼ë¦¬", expanded=False):
                st.markdown("### ëª¨ë¸ í‰ê°€ ë°ì´í„° ë¶„ì„ì„ ìœ„í•œ NRQL ì¿¼ë¦¬")
                
                # ë¼ì´ë¸ŒëŸ¬ë¦¬ í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ìƒ˜í”Œ ì¿¼ë¦¬ ê°€ì ¸ì˜¤ê¸° (Knowledge Base ID ì—†ì´)
                sample_queries = get_sample_nrql_queries(
                    trace_id=st.session_state.trace_id,
                    completion_id=st.session_state.current_completion_id,
                    conversation_id=st.session_state.conversation_id,
                    kb_id=None  # Knowledge Base ì—†ìŒ
                )
                
                # ì¿¼ë¦¬ ê²°ê³¼ê°€ ì—†ëŠ” ì´ìœ ì— ëŒ€í•œ ì„¤ëª… ì¶”ê°€
                st.warning("""
                **ì°¸ê³ **: ì¿¼ë¦¬ ê²°ê³¼ê°€ ì—†ëŠ” ê²½ìš° ë‹¤ìŒê³¼ ê°™ì€ ì´ìœ ê°€ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤:
                
                1. ì•„ì§ í‰ê°€ ë°ì´í„°ê°€ ìˆ˜ì§‘ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë¨¼ì € ëª‡ ê°œì˜ ëª¨ë¸ í‰ê°€ë¥¼ ì œì¶œí•´ë³´ì„¸ìš”.
                2. ì´ë²¤íŠ¸ íƒ€ì… ì´ë¦„ì´ ì‹¤ì œ New Relicì— ê¸°ë¡ëœ ì´ë¦„ê³¼ ë‹¤ë¥¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
                3. New Relic ê³„ì • ì„¤ì •ì—ì„œ ì‚¬ìš©ì ì •ì˜ ì´ë²¤íŠ¸ ìˆ˜ì§‘ì´ í™œì„±í™”ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.
                4. ì‹œê°„ ë²”ìœ„ë¥¼ ë” ë„“ê²Œ ì„¤ì •í•˜ì—¬ í™•ì¸í•´ ë³´ì„¸ìš”.
                
                í‰ê°€ ì œì¶œ í›„ ë°ì´í„°ê°€ New Relicì— í‘œì‹œë˜ëŠ” ë° ì•½ê°„ì˜ ì‹œê°„ì´ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
                """)
                
                # ìƒ˜í”Œ ì¿¼ë¦¬ í‘œì‹œ
                for title, query in sample_queries.items():
                    st.markdown(f"**{title}:**")
                    st.code(query)
        
        # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ í‘œì‹œ
        if st.session_state.current_system_prompt:
            with st.expander("ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸", expanded=False):
                st.code(st.session_state.current_system_prompt)
        
        # Knowledge Base ê²€ìƒ‰ ê²°ê³¼ëŠ” í‘œì‹œí•˜ì§€ ì•ŠìŒ (ê²€ìƒ‰ ì•ˆí•¨)
        # if st.session_state.current_search_results:
        #     with st.expander("ê²€ìƒ‰ ê²°ê³¼", expanded=False):
        #         ...
        
        # ì‹¤í–‰ ì •ë³´ í‘œì‹œ
        if st.session_state.raw_result:
            with st.expander("ì‹¤í–‰ ì •ë³´", expanded=False):
                # st.metric("ê²€ìƒ‰ ì‹œê°„", f"{st.session_state.raw_result.get('search_time_ms', 0)} ms")
                st.metric("LLM ì‘ë‹µ ì‹œê°„", f"{st.session_state.raw_result.get('llm_time_ms', 0)} ms")
                st.metric("ì´ ì²˜ë¦¬ ì‹œê°„", f"{st.session_state.raw_result.get('total_time_ms', 0)} ms")
                st.metric("í† í° ìˆ˜", st.session_state.raw_result.get('token_count', 0))
                
                # ì‚¬ìš©ëœ íŒŒë¼ë¯¸í„° ì •ë³´ ì¶”ê°€
                st.markdown("**ì‚¬ìš©ëœ íŒŒë¼ë¯¸í„°:**")
                st.markdown(f"- Temperature: {st.session_state.raw_result.get('temperature', 'N/A')}")
                st.markdown(f"- Top-p: {st.session_state.raw_result.get('top_p', 'N/A')}")
                st.markdown(f"- ì´ í† í°: {st.session_state.raw_result.get('total_tokens', 'N/A')}")
                st.markdown(f"- í”„ë¡¬í”„íŠ¸ í† í°: {st.session_state.raw_result.get('prompt_tokens', 'N/A')}")
        
        # ìƒˆ ëŒ€í™” ì‹œì‘ ë²„íŠ¼
        if st.button("ìƒˆ ëŒ€í™” ì‹œì‘"):
            # ì´ì „ í‰ê°€ ìƒíƒœ í‚¤ë¥¼ ëª¨ë‘ ì°¾ì•„ì„œ ì´ˆê¸°í™”
            eval_keys = [key for key in st.session_state.keys() if key.startswith("eval_")]
            for key in eval_keys:
                del st.session_state[key]
                
            # ì´ì „ ìŠ¬ë¼ì´ë”/ìœ„ì ¯ í‚¤ ì´ˆê¸°í™”
            widget_keys = [key for key in st.session_state.keys() if 
                          any(key.startswith(prefix) for prefix in 
                              ["overall_score_", "relevance_score_", "accuracy_score_", 
                               "completeness_score_", "coherence_score_", "helpfulness_score_",
                               "response_time_score_", "query_type_", "domain_", "feedback_comment_",
                               "submit_", "reset_log_", "test_eval_"])]
            for key in widget_keys:
                if key in st.session_state:
                    del st.session_state[key]
            
            # ê¸°ë³¸ ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
            st.session_state.trace_id = str(uuid.uuid4())
            st.session_state.conversation_id = str(uuid.uuid4())
            st.session_state.messages = []
            st.session_state.current_completion_id = None
            st.session_state.raw_result = {}
            # st.session_state.current_search_results = []  # Knowledge Base ì—†ìœ¼ë‹ˆ ì‚¬ìš© ì•ˆí•¨
            # í˜„ì¬ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ë¥¼ ì‚¬ìš©ì ì„¤ì •ìœ¼ë¡œ ì—…ë°ì´íŠ¸
            st.session_state.current_system_prompt = f"{st.session_state.user_role_prompt}\n\n{st.session_state.user_system_prompt}"
            st.session_state.message_count = 0
            
            # ì‘ë‹µ í‰ê°€ ìˆ˜ì§‘ê¸° ì´ˆê¸°í™”
            try:
                # ì‘ë‹µ í‰ê°€ ìˆ˜ì§‘ê¸° ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
                if "response_evaluation_collector" in st.session_state:
                    # ë¼ì´ë¸ŒëŸ¬ë¦¬ í•¨ìˆ˜ ì‚¬ìš©í•˜ì—¬ í‰ê°€ ìˆ˜ì§‘ê¸° ì´ˆê¸°í™”
                    reset_evaluation_collector(collector_session_key="response_evaluation_collector")
                
                # ìƒˆë¡œìš´ ìˆ˜ì§‘ê¸° ì´ˆê¸°í™”
                init_response_evaluation_collector(
                    application_name=APP_NAME,
                    trace_id=st.session_state.trace_id,
                    completion_id=None,
                    session_id=st.session_state.conversation_id,
                    collector_session_key="response_evaluation_collector"
                )
            except Exception as e:
                st.warning(f"í‰ê°€ ìˆ˜ì§‘ê¸° ì´ˆê¸°í™” ì¤‘ ì˜¤ë¥˜: {str(e)}")
                
            st.rerun()
    
    with main_col:
        # ì±„íŒ… ê¸°ë¡ í‘œì‹œ
        for message in st.session_state.messages:
            with st.chat_message(message["role"]):
                st.markdown(message["content"])
        
        # ì‚¬ìš©ì ì…ë ¥
        user_input = st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”")
        
        if user_input:
            # ì‚¬ìš©ì ë©”ì‹œì§€ í‘œì‹œ (ì›ë³¸ ì§ˆë¬¸ë§Œ í‘œì‹œ)
            with st.chat_message("user"):
                st.markdown(user_input)
            
            # ë©”ì‹œì§€ ì €ì¥ (ì›ë³¸ ì§ˆë¬¸ë§Œ ì €ì¥)
            st.session_state.messages.append({"role": "user", "content": user_input})
            
            # ì‘ë‹µ ìƒì„± - Knowledge Base ì—†ì´ ì§ì ‘ Bedrock í˜¸ì¶œ
            with st.chat_message("assistant"):
                with st.spinner("ë‹µë³€ ìƒì„± ì¤‘..."):
                    response, result_info = run_direct_bedrock_workflow(user_input)
                    
                    if response:
                        st.markdown(response)
                        
                        # ê²°ê³¼ ì •ë³´ ì €ì¥
                        st.session_state.raw_result = result_info
                        
                        # ë©”ì‹œì§€ ì €ì¥
                        st.session_state.messages.append({"role": "assistant", "content": response})
                        
                        # ì‘ë‹µ í‰ê°€ ìˆ˜ì§‘ê¸° ì—…ë°ì´íŠ¸
                        try:
                            if result_info:
                                # ìˆ˜ì§‘ê¸° ì—…ë°ì´íŠ¸
                                init_response_evaluation_collector(
                                    application_name=APP_NAME,
                                    trace_id=result_info.get('trace_id'),
                                    completion_id=result_info.get('completion_id'),
                                    session_id=st.session_state.conversation_id,
                                    collector_session_key="response_evaluation_collector"
                                )
                        except Exception as e:
                            st.warning(f"ì‘ë‹µ í‰ê°€ ìˆ˜ì§‘ê¸° ì—…ë°ì´íŠ¸ ì¤‘ ì˜¤ë¥˜: {str(e)}")
                            
                    else: # if response (no response generated)
                        st.warning("ëª¨ë¸ë¡œë¶€í„° ì‘ë‹µì„ ë°›ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
                # ì—¬ê¸°ì„œ with st.spinner ë
            # ì—¬ê¸°ì„œ with st.chat_message("assistant") ë
        # ì—¬ê¸°ì„œ if user_input ë

    # --- ëª¨ë¸ ì‘ë‹µ í‰ê°€ UI ì„¹ì…˜ ---
    # ê°€ì¥ ë§ˆì§€ë§‰ ë©”ì‹œì§€ê°€ ì–´ì‹œìŠ¤í„´íŠ¸ì˜ ì‘ë‹µì¼ ê²½ìš°ì—ë§Œ í‰ê°€ UIë¥¼ í‘œì‹œí•©ë‹ˆë‹¤.
    if st.session_state.messages and st.session_state.messages[-1]["role"] == "assistant":
        
        eval_key = f"eval_{st.session_state.message_count}"
        
        # í˜„ì¬ raw_result ì •ë³´ë¥¼ ì•ˆì „í•˜ê²Œ ê°€ì ¸ì˜¤ê¸°
        current_raw_result = st.session_state.get("raw_result", {})
        
        # í‰ê°€ ì„¹ì…˜ í‘œì‹œ
        st.markdown("### ëª¨ë¸ ì‘ë‹µ í‰ê°€")
        
        # ë¼ì´ë¸ŒëŸ¬ë¦¬ í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•œ Streamlit ì‘ë‹µ í‰ê°€ UI - Knowledge Base ì •ë³´ ì—†ì´
        try:
            create_evaluation_ui(
                eval_key=eval_key,
                trace_id=current_raw_result.get('trace_id'),
                completion_id=current_raw_result.get('completion_id'),
                model_id=MODEL_ID,
                kb_id=None,  # Knowledge Base ì—†ìŒ
                kb_name=None,  # Knowledge Base ì—†ìŒ
                kb_used_in_query=False,  # Knowledge Base ì‚¬ìš© ì•ˆí•¨
                response_time_ms=current_raw_result.get('total_time_ms'),
                total_tokens=current_raw_result.get('total_tokens'),
                prompt_tokens=current_raw_result.get('prompt_tokens'),
                completion_tokens=current_raw_result.get('token_count'),
                temperature=current_raw_result.get('temperature'),
                top_p=current_raw_result.get('top_p'),
                application_name=APP_NAME,
                use_number_input=True,  # ìŠ¬ë¼ì´ë” ëŒ€ì‹  ìˆ«ì ì…ë ¥ ì‚¬ìš©
                submit_button_text="í‰ê°€ ì œì¶œ",
                evaluation_source="streamlit"
            )
        except Exception as e:
            st.error(f"í‰ê°€ UI ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            # ê¸°ë³¸ í‰ê°€ UI ëŒ€ì‹  ìˆ˜ë™ í‰ê°€ ì œì¶œ í¼ í‘œì‹œ
            st.write("ëŒ€ì²´ í‰ê°€ ë°©ì‹ì„ ì‚¬ìš©í•©ë‹ˆë‹¤:")
            with st.form("manual_evaluation_form"):
                overall_score = st.number_input("ì „ì²´ ë§Œì¡±ë„", min_value=1, max_value=10, value=5)
                relevance = st.number_input("ì§ˆë¬¸ ê´€ë ¨ì„±", min_value=1, max_value=10, value=5)
                accuracy = st.number_input("ì •í™•ì„±", min_value=1, max_value=10, value=5)
                submit = st.form_submit_button("í‰ê°€ ì œì¶œ")
                
                if submit:
                    try:
                        # ìˆ˜ë™ìœ¼ë¡œ í‰ê°€ ì œì¶œ - ë¼ì´ë¸ŒëŸ¬ë¦¬ í•¨ìˆ˜ ì§ì ‘ ì‚¬ìš© (Knowledge Base ì •ë³´ ì—†ì´)
                        evaluation_data = {
                            "model_id": MODEL_ID,
                            "overall_score": overall_score,
                            "relevance_score": relevance,
                            "accuracy_score": accuracy,
                            "kb_id": None,  # Knowledge Base ì—†ìŒ
                            "kb_name": None,  # Knowledge Base ì—†ìŒ
                            "evaluation_source": "streamlit-manual",
                            "trace_id": current_raw_result.get('trace_id'),
                            "completion_id": current_raw_result.get('completion_id'),
                            "temperature": current_raw_result.get('temperature'),
                            "top_p": current_raw_result.get('top_p'),
                            "application_name": APP_NAME
                        }
                        
                        result = send_evaluation_with_newrelic_agent(
                            event_data=evaluation_data,
                            event_type="LlmUserResponseEvaluation"
                        )
                        
                        if result:
                            st.success("í‰ê°€ê°€ ì„±ê³µì ìœ¼ë¡œ ì œì¶œë˜ì—ˆìŠµë‹ˆë‹¤!")
                    except Exception as submit_error:
                        st.error(f"í‰ê°€ ì œì¶œ ì¤‘ ì˜¤ë¥˜: {str(submit_error)}")
        
        # ê°œë°œì ë„êµ¬
        st.markdown("### ê°œë°œì ë„êµ¬")
        show_debug = st.checkbox("ë””ë²„ê¹… ì •ë³´ í‘œì‹œ", value=False, key=f"show_debug_{eval_key}")
        
        if show_debug:
            # ê°„ë‹¨í•œ ë””ë²„ê¹… ì •ë³´ ì§ì ‘ í‘œì‹œ
            st.code(f"""
            íŠ¸ë ˆì´ìŠ¤ ID: {current_raw_result.get('trace_id')}
            ì™„ì„± ID: {current_raw_result.get('completion_id')}
            ëª¨ë¸ ID: {MODEL_ID}
            ì‘ë‹µ ì‹œê°„: {current_raw_result.get('total_time_ms')} ms
            ì´ í† í°: {current_raw_result.get('total_tokens')}
            Knowledge Base ì‚¬ìš©: ì—†ìŒ (ì§ì ‘ í˜¸ì¶œ)
            """)
            
            # ìˆ˜ë™ í…ŒìŠ¤íŠ¸ í‰ê°€ ì „ì†¡ ë²„íŠ¼
            if st.button("í…ŒìŠ¤íŠ¸ í‰ê°€ ì „ì†¡", key=f"test_eval_manual_{eval_key}"):
                try:
                    # í…ŒìŠ¤íŠ¸ í‰ê°€ ì œì¶œ - ë¼ì´ë¸ŒëŸ¬ë¦¬ í•¨ìˆ˜ ì§ì ‘ ì‚¬ìš© (Knowledge Base ì •ë³´ ì—†ì´)
                    evaluation_data = {
                        "model_id": MODEL_ID,
                        "overall_score": 8,
                        "kb_id": None,  # Knowledge Base ì—†ìŒ
                        "kb_name": None,  # Knowledge Base ì—†ìŒ
                        "evaluation_source": "streamlit-manual-test",
                        "trace_id": current_raw_result.get('trace_id'),
                        "completion_id": current_raw_result.get('completion_id'),
                        "temperature": current_raw_result.get('temperature'),
                        "top_p": current_raw_result.get('top_p'),
                        "application_name": APP_NAME
                    }
                    
                    test_result = send_evaluation_with_newrelic_agent(
                        event_data=evaluation_data,
                        event_type="LlmUserResponseEvaluation"
                    )
                    
                    if test_result:
                        st.success(f"í…ŒìŠ¤íŠ¸ í‰ê°€ ì „ì†¡ ì„±ê³µ: ID={test_result.get('id')}")
                except Exception as e:
                    st.error(f"í…ŒìŠ¤íŠ¸ í‰ê°€ ì „ì†¡ ì˜¤ë¥˜: {str(e)}")

    # í‘¸í„°
    st.markdown("---")
    st.markdown(
        "ì´ ì•±ì€ nr-bedrock-observability-python v2.0.2 ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•˜ì—¬ "
        "AWS Bedrock API ì§ì ‘ í˜¸ì¶œì„ ëª¨ë‹ˆí„°ë§í•˜ë©°, "
        "Knowledge Base ì—†ì´ Claude 3.5 Sonnet ëª¨ë¸ê³¼ ì§ì ‘ ëŒ€í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. "
        "temperatureì™€ top_p íŒŒë¼ë¯¸í„°ë¥¼ í¬í•¨í•œ í† í° ì²˜ë¦¬ì™€ ì´ë²¤íŠ¸ ìˆ˜ì§‘ì´ ê°œì„ ëœ Streamlit í‰ê°€ UIë¥¼ ì œê³µí•©ë‹ˆë‹¤."
    )

if __name__ == "__main__":
    build_ui() 